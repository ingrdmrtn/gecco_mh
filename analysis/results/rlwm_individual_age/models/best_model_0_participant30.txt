def cognitive_model1(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    Surprise-gated WM with shared decay and age-modulated temperature.

    Core idea:
    - RL learns with a standard delta rule.
    - WM updates are gated by surprise and reward, with stronger gating in low set size.
    - Both RL and WM traces decay toward an uninformative prior at a rate controlled by a shared decay parameter.
    - Arbitration uses the same surprise-derived gate as a dynamic WM weight.
    - Younger participants have effectively higher inverse temperature (more exploitative).

    Parameters
    ----------
    states : array-like
        State index per trial within block (0..nS-1).
    actions : array-like
        Chosen action per trial (0..2).
    rewards : array-like
        Reward per trial (0 or 1).
    blocks : array-like
        Block index per trial.
    set_sizes : array-like
        Set size per trial (3 or 6).
    age : array-like
        Participant age repeated per trial.
    model_parameters : list or array
        [lr, beta_base, wm_beta, wm_gate_surprise, decay, age_temp_shift]
        - lr: RL learning rate (0..1).
        - beta_base: baseline inverse temperature (>0), scaled by 10 internally.
        - wm_beta: WM inverse temperature (>0).
        - wm_gate_surprise: sensitivity of WM gate to surprise/reward and set size.
        - decay: shared decay toward uniform for both Q and W (0..1).
        - age_temp_shift: temperature scaling for older group (>=0). Applied as exp(-age_temp_shift*age_group).

    Returns
    -------
    float
        Negative log-likelihood of the observed choices.
    """
    lr, beta_base, wm_beta, wm_gate_surprise, decay, age_temp_shift = model_parameters
    softmax_beta = beta_base * 10.0
    softmax_beta_wm = wm_beta
    age_group = 0 if age[0] <= 45 else 1

    blocks_log_p = 0.0

    for b in np.unique(blocks):
        mask = (blocks == b)
        block_actions = actions[mask]
        block_rewards = rewards[mask]
        block_states = states[mask]
        block_set_sizes = set_sizes[mask]

        nA = 3
        nS = int(block_set_sizes[0])

        beta_eff = softmax_beta * np.exp(-age_temp_shift * age_group)
        beta_wm_eff = softmax_beta_wm  # WM is precise but parameterized

        q = (1.0 / nA) * np.ones((nS, nA))
        w = (1.0 / nA) * np.ones((nS, nA))
        w_0 = (1.0 / nA) * np.ones((nS, nA))
        q_0 = (1.0 / nA) * np.ones((nS, nA))

        log_p = 0.0
        for t in range(len(block_states)):
            a = int(block_actions[t])
            s = int(block_states[t])
            r = float(block_rewards[t])

            Q_s = q[s, :]
            p_rl = 1.0 / np.sum(np.exp(beta_eff * (Q_s - Q_s[a])))

            W_s = w[s, :]
            p_wm = 1.0 / np.sum(np.exp(beta_wm_eff * (W_s - W_s[a])))

            pe = abs(r - Q_s[a])  # 0..1
            size_scale = (nS - 3) / 3.0  # 0 for 3, 1 for 6

            gate_input = (r - 0.5) + pe - 0.5 * size_scale - 0.2 * age_group
            wm_weight = 1.0 / (1.0 + np.exp(-wm_gate_surprise * gate_input))
            wm_weight = np.clip(wm_weight, 0.0, 1.0)

            p_total = wm_weight * p_wm + (1.0 - wm_weight) * p_rl
            log_p += np.log(max(p_total, 1e-12))

            delta = r - Q_s[a]
            q = (1.0 - decay) * q + decay * q_0
            q[s, a] += lr * delta

            w = (1.0 - decay) * w + decay * w_0
            w[s, a] += wm_weight * (r - w[s, a])

        blocks_log_p += log_p

    return -blocks_log_p