Here are three alternative RL+WM cognitive models that respect your template and constraints. Each function is standalone, uses all parameters meaningfully (≤6), accounts for set size (3 vs 6) and age group (young vs old), and returns the negative log-likelihood of the participant’s choices.

def cognitive_model1(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    RL+WM mixture with prediction-error-gated WM weight and load- and age-dependent WM decay.

    Idea:
    - Choices come from a mixture of RL softmax and WM softmax.
    - The WM mixture weight increases when the unsigned prediction error is small (stimulus–action known),
      is reduced by higher set size (load), and is boosted for younger adults.
    - WM traces decay toward uniform faster under load and for older adults.

    Parameters (model_parameters):
    - lr: RL learning rate in [0,1].
    - wm_weight: baseline WM mixture weight (transformed via logit-sigmoid to (0,1)).
    - softmax_beta: RL inverse temperature; internally scaled by x10.
    - wm_decay: base WM decay rate per trial (0..1), amplified by set size and age.
    - pe_sensitivity: how strongly small unsigned PE increases WM mixture weight (>0 increases gating).
    - age_wm_mod: adds to WM mixture weight pre-sigmoid for young, subtracts for old.

    Returns:
    - Negative log-likelihood of observed choices.
    """
    lr, wm_weight, softmax_beta, wm_decay, pe_sensitivity, age_wm_mod = model_parameters
    softmax_beta *= 10.0  # consistent with template

    age_group = 0 if age[0] <= 45 else 1

    eps = 1e-12
    blocks_log_p = 0.0

    def logit(p):
        p = min(max(p, 1e-6), 1 - 1e-6)
        return np.log(p) - np.log(1 - p)

    for b in np.unique(blocks):

        block_actions = actions[blocks == b]
        block_rewards = rewards[blocks == b]
        block_states = states[blocks == b]
        block_set_sizes = set_sizes[blocks == b]

        nA = 3
        nS = int(block_set_sizes[0])

        q = (1.0 / nA) * np.ones((nS, nA))
        w = (1.0 / nA) * np.ones((nS, nA))
        w_0 = (1.0 / nA) * np.ones((nS, nA))

        softmax_beta_wm = 50.0  # very deterministic, per template
        log_p = 0.0

        # Load factor: 3 states -> 1.0, 6 states -> 0.5
        load_factor = 3.0 / nS

        # Age modulation to WM mixture weight pre-sigmoid
        age_term = age_wm_mod * (1 - 2 * age_group)  # +x for young, -x for old

        for t in range(len(block_states)):

            a = int(block_actions[t])
            s = int(block_states[t])
            r = block_rewards[t]

            Q_s = q[s, :]
            W_s = w[s, :]

            # RL policy
            p_rl = 1.0 / np.sum(np.exp(softmax_beta * (Q_s - Q_s[a])))

            # WM policy
            p_wm = 1.0 / np.sum(np.exp(softmax_beta_wm * (W_s - W_s[a])))

            # Unsigned PE for gating WM: small |PE| -> higher WM reliance
            delta = r - Q_s[a]
            pe_gate = pe_sensitivity * (1.0 - np.minimum(1.0, np.abs(delta)))  # in [0, pe_sensitivity]

            # Combine baseline WM weight, load, age, and PE gating via a logistic transform
            base_logit = logit(wm_weight)
            load_log_term = np.log(load_factor + 1e-12)  # penalize weight under higher load
            wm_weight_eff = 1.0 / (1.0 + np.exp(-(base_logit + pe_gate + load_log_term + age_term)))

            # Mixture policy
            p_total = wm_weight_eff * p_wm + (1.0 - wm_weight_eff) * p_rl
            p_total = max(p_total, eps)
            log_p += np.log(p_total)

            # RL update
            q[s, a] += lr * delta

            # WM decay/forgetting toward uniform, accelerated by load and age
            # Effective decay per trial
            decay_eff = 1.0 - (1.0 - wm_decay) ** (nS / 3.0)  # higher for larger nS
            decay_eff *= (1.0 + 0.5 * age_group)  # older forget faster
            decay_eff = max(0.0, min(1.0, decay_eff))

            w[s, :] = (1.0 - decay_eff) * w[s, :] + decay_eff * w_0[s, :]

            # WM write: reward stamps the chosen action as correct; no-reward weakly suppresses it
            if r > 0:
                one_hot = np.zeros(nA)
                one_hot[a] = 1.0
                w[s, :] = 0.3 * w[s, :] + 0.7 * one_hot
            else:
                # Mild anti-update on the chosen action to discourage it
                w[s, a] = 0.7 * w[s, a] + 0.3 * (1.0 / nA)

        blocks_log_p += log_p

    return -blocks_log_p


def cognitive_model2(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    RL+WM mixture with load- and age-dependent lapse and leaky WM; epsilon-greedy lapses.

    Idea:
    - Choices are from a mixture of RL and WM, but with an additional lapse (epsilon) to uniform random choice.
    - Lapses increase with set size and in older adults.
    - WM leaky integration with reward-driven "win-stay" emphasis; forgetting also scales with load.

    Parameters (model_parameters):
    - lr: RL learning rate in [0,1].
    - wm_weight: baseline WM mixture weight (0..1, passed through logit-sigmoid).
    - softmax_beta: RL inverse temperature; internally scaled by x10.
    - eps_base: baseline lapse probability (0..1), transformed via logit-sigmoid.
    - age_eps_boost: additive boost to lapse pre-sigmoid for older adults.
    - wm_leak: WM leak (0..1) controlling how strongly WM drifts toward uniform per trial.

    Returns:
    - Negative log-likelihood of observed choices.
    """
    lr, wm_weight, softmax_beta, eps_base, age_eps_boost, wm_leak = model_parameters
    softmax_beta *= 10.0

    age_group = 0 if age[0] <= 45 else 1

    eps_num = 1e-12
    blocks_log_p = 0.0

    def to_logit(p):
        p = min(max(p, 1e-6), 1 - 1e-6)
        return np.log(p) - np.log(1 - p)

    for b in np.unique(blocks):

        block_actions = actions[blocks == b]
        block_rewards = rewards[blocks == b]
        block_states = states[blocks == b]
        block_set_sizes = set_sizes[blocks == b]

        nA = 3
        nS = int(block_set_sizes[0])

        q = (1.0 / nA) * np.ones((nS, nA))
        w = (1.0 / nA) * np.ones((nS, nA))
        w_0 = (1.0 / nA) * np.ones((nS, nA))

        softmax_beta_wm = 50.0
        log_p = 0.0

        # WM mixture weight (constant within block but depends on load via a log term)
        wm_weight_eff = 1.0 / (1.0 + np.exp(-(to_logit(wm_weight) + np.log((3.0 / nS) + 1e-12))))
        # Lapse: depends on base, load (more load => more lapses), and age (older => more lapses)
        lapse_logit = to_logit(eps_base) + np.log((nS / 3.0) + 1e-12) + age_eps_boost * age_group
        eps_lapse = 1.0 / (1.0 + np.exp(-lapse_logit))

        # WM leak increases with load
        leak_eff = 1.0 - (1.0 - wm_leak) ** (nS / 3.0)

        for t in range(len(block_states)):

            a = int(block_actions[t])
            s = int(block_states[t])
            r = block_rewards[t]

            Q_s = q[s, :]
            W_s = w[s, :]

            # RL policy
            p_rl = 1.0 / np.sum(np.exp(softmax_beta * (Q_s - Q_s[a])))

            # WM policy
            p_wm = 1.0 / np.sum(np.exp(softmax_beta_wm * (W_s - W_s[a])))

            # Mixture then lapse to uniform
            p_mix = wm_weight_eff * p_wm + (1.0 - wm_weight_eff) * p_rl
            p_total = (1.0 - eps_lapse) * p_mix + eps_lapse * (1.0 / nA)
            p_total = max(p_total, eps_num)
            log_p += np.log(p_total)

            # RL update
            delta = r - Q_s[a]
            q[s, a] += lr * delta

            # WM leak toward uniform
            w[s, :] = (1.0 - leak_eff) * w[s, :] + leak_eff * w_0[s, :]

            # WM "win-stay" update on reward; "lose-soften" otherwise
            if r > 0:
                one_hot = np.zeros(nA)
                one_hot[a] = 1.0
                w[s, :] = 0.4 * w[s, :] + 0.6 * one_hot
            else:
                # Push slightly away from the chosen action but keep others similar
                w[s, a] = 0.8 * w[s, a] + 0.2 * (1.0 / nA)

        blocks_log_p += log_p

    return -blocks_log_p


def cognitive_model3(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    RL+WM mixture with capacity-limited WM via slots and age-modulated inverse temperature.

    Idea:
    - WM effectiveness is limited by a capacity parameter (slots); when set size exceeds capacity,
      WM decays strongly toward uniform (interference).
    - Older adults have lower effective inverse temperature in RL (noisier RL policy).
    - WM updates are write-then-forget with capacity-driven interference.

    Parameters (model_parameters):
    - lr: RL learning rate in [0,1].
    - wm_weight: baseline WM mixture weight (0..1) passed through logit-sigmoid.
    - softmax_beta: base RL inverse temperature; scaled by x10, then age-dampened.
    - slots: effective WM capacity (in states); higher slots => less interference for larger sets.
    - wm_decay: base WM decay component combined with capacity interference.

    Returns:
    - Negative log-likelihood of observed choices.
    """
    lr, wm_weight, softmax_beta, slots, wm_decay = model_parameters
    softmax_beta *= 10.0

    age_group = 0 if age[0] <= 45 else 1

    eps = 1e-12
    blocks_log_p = 0.0

    def to_logit(p):
        p = min(max(p, 1e-6), 1 - 1e-6)
        return np.log(p) - np.log(1 - p)

    for b in np.unique(blocks):

        block_actions = actions[blocks == b]
        block_rewards = rewards[blocks == b]
        block_states = states[blocks == b]
        block_set_sizes = set_sizes[blocks == b]

        nA = 3
        nS = int(block_set_sizes[0])

        q = (1.0 / nA) * np.ones((nS, nA))
        w = (1.0 / nA) * np.ones((nS, nA))
        w_0 = (1.0 / nA) * np.ones((nS, nA))

        # Age-modulated RL temperature: older -> noisier (lower inverse temp)
        beta_age_scale = 1.0 / (1.0 + 0.5 * age_group)
        softmax_beta_eff = softmax_beta * beta_age_scale

        softmax_beta_wm = 50.0
        log_p = 0.0

        # Capacity interference factor: 0 if nS <= slots_eff, grows as nS exceeds capacity
        slots_eff = max(1.0, float(slots) * (1.0 - 0.3 * age_group))  # fewer effective slots when older
        overload = max(0.0, (nS - slots_eff) / max(1.0, nS))
        # Convert overload into additional decay
        decay_from_capacity = 1.0 - (1.0 - wm_decay) * (1.0 - overload)

        # WM mixture weight reduced under load beyond capacity
        wm_weight_eff = 1.0 / (1.0 + np.exp(-(to_logit(wm_weight) + np.log((slots_eff / nS) + 1e-12))))

        for t in range(len(block_states)):

            a = int(block_actions[t])
            s = int(block_states[t])
            r = block_rewards[t]

            Q_s = q[s, :]
            W_s = w[s, :]

            # RL policy
            p_rl = 1.0 / np.sum(np.exp(softmax_beta_eff * (Q_s - Q_s[a])))

            # WM policy
            p_wm = 1.0 / np.sum(np.exp(softmax_beta_wm * (W_s - W_s[a])))

            # Mixture
            p_total = wm_weight_eff * p_wm + (1.0 - wm_weight_eff) * p_rl
            p_total = max(p_total, eps)
            log_p += np.log(p_total)

            # RL update
            delta = r - Q_s[a]
            q[s, a] += lr * delta

            # WM write-then-forget: first write reward, then apply capacity-driven decay
            if r > 0:
                one_hot = np.zeros(nA)
                one_hot[a] = 1.0
                w[s, :] = 0.5 * w[s, :] + 0.5 * one_hot
            else:
                # Mild penalty to chosen action on no-reward
                w[s, a] = 0.8 * w[s, a] + 0.2 * (1.0 / nA)

            # Apply decay/interference toward uniform due to capacity overload
            w[s, :] = (1.0 - decay_from_capacity) * w[s, :] + decay_from_capacity * w_0[s, :]

        blocks_log_p += log_p

    return -blocks_log_p

Notes on set size and age effects:
- Model 1: WM weight increases with small prediction error, but is reduced by set size (3 vs 6; via log load factor) and by age (young boosted, old reduced). WM decay increases with set size and age.
- Model 2: Lapse probability increases with set size and age; WM leak also increases with set size. WM and RL are mixed with a fixed (load-adjusted) weight.
- Model 3: WM capacity limits are explicit via slots; when set size exceeds slots, WM decays more and WM weight is reduced. Older adults have fewer effective slots and noisier RL (lower inverse temperature).