loop:
  max_iterations: 5
  max_independent_runs: 1

task:
  name: "two_step_factors"
  description: |
    In this task, the participant makes a sequence of choices to earn money. 
    On each trial, they first select between two images, which probabilistically 
    transitions them to one of two possible second-stage screens. 
    This transition relies on fixed rules; for example, one image might have a 
    70% chance of leading to screen A (a "common" transition) and a 30% chance 
    of leading to screen B (a "rare" transition). 
    Once in the second stage, the participant chooses between two new images, 
    each carrying its own probability of yielding a 25-cent reward. 
    Crucially, these reward probabilities drift slowly over time between 25% and 75%, 
    meaning the participant must continuously adapt to figure out which final image 
    is currently paying out the most.

  goal: |
    Your task: Propose **{models_per_iteration} new cognitive models** as Python functions:
    {model_names}

data:
  max_prompt_trials: 10
  path: "data_g_2019/preprocessed_study2_no_baseline.csv"
  id_column: "participant"
  input_columns: ["choice_1", "state", "choice_2", "reward"]
  data2text_function: "narrative"

  narrative_template: |
    The participant chose spaceship {choice_1}, traveled to second stage state {state},
    made choice {choice_2}, and received {reward} coins.

  value_mappings:
    choice_1:
      "0": "A"
      "1": "U"
    state:
      "0": "X"
      "1": "Y"
    choice_2:
      "0": "W"
      "1": "S"

  splits:
    prompt: "[1:3]"
    eval: "[4:14]"
    test: "[14:]"

llm:
  provider: "r1"
  base_model: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
  temperature: 0.1
  max_tokens: 2048
  max_output_tokens: 2048
  system_prompt: |
    You are a renowned cognitive scientist and expert Python programmer.
    You will be given participant data from a two-step decision-making task.
    Your job is to propose cognitive models, expressed as Python functions,
    that explain how participants make their decisions over time.

  models_per_iteration: 3
  include_feedback: true
  guardrails:
    - "Each model must be a standalone Python function."
    - "Function names must be `cognitive_model1`, `cognitive_model2`, etc."
    - "Take as input: `action_1, state, action_2, reward, model_parameters`."
    - "Return the **negative log-likelihood** of observed choices."
    - "Use all parameters meaningfully (no unused params)."
    - "Include a clear docstring for the model and each parameter."
    - "Parameter bounds: [0,1] for most; [0,10] for softmax `beta` (inverse temperature). Please refer to the template for how these are defined."
    - "Do NOT include any package imports inside the code you write. Assume all packages are already imported."

  template_model: |
    def cognitive_model(action_1, state, action_2, reward, model_parameters):
        """Example model illustrating format only (do not reuse logic).
        Bounds:
        learning_rate: [0,1]
        beta: [0,10]
        """
        learning_rate, beta = model_parameters
        n_trials = len(action_1)

        transition_matrix = np.array([[0.7, 0.3], [0.3, 0.7]])
        p_choice_1 = np.zeros(n_trials)
        p_choice_2 = np.zeros(n_trials)
        q_stage1_mf = np.zeros(2)
        q_stage2_mf = np.zeros((2, 2))

        for trial in range(n_trials):
            max_q_stage2 = np.max(q_stage2_mf, axis=1)
            q_stage1_mb = transition_matrix @ max_q_stage2
            exp_q1 = np.exp(beta * q_stage1_mb)
            probs_1 = exp_q1 / np.sum(exp_q1)
            p_choice_1[trial] = probs_1[action_1[trial]]
            state_idx = state[trial]
            exp_q2 = np.exp(beta * q_stage2_mf[state_idx])
            probs_2 = exp_q2 / np.sum(exp_q2)
            p_choice_2[trial] = probs_2[action_2[trial]]
            delta_stage1 = q_stage2_mf[state_idx, action_2[trial]] - q_stage1_mf[action_1[trial]]
            q_stage1_mf[action_1[trial]] += learning_rate * delta_stage1
            delta_stage2 = reward[trial] - q_stage2_mf[state_idx, action_2[trial]]
            q_stage2_mf[state_idx, action_2[trial]] += learning_rate * delta_stage2

        eps = 1e-10
        log_loss = -(np.sum(np.log(p_choice_1 + eps)) + np.sum(np.log(p_choice_2 + eps)))
        return log_loss

evaluation:
  metric: "bic"
  optimizer: "L-BFGS-B"

feedback:
  type: "llm"

individual_differences_eval:
  data_path: "data_g_2019/self_report_study2.csv"
  id_column: "subj"
  behavioral_id_column: "subject_id"
  predictors: ["Factor1", "Factor2", "Factor3"]
  covariates: ["age", "gender"]
