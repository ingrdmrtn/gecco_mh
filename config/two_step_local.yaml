loop:
  max_iterations: 5
  max_independent_runs: 1

task:
  name: "two_step_task"
  description: |
    Participants play a two-step decision task to collect as many gold coins as possible.
    On each trial, they choose between two spaceships (A or U),
    each probabilistically traveling to one of two planets (X or Y).
    Spaceship A commonly travels to planet X, and spaceship U commonly travels to planet Y. Sometimes, rare transitions occur.
    Planet X has aliens W and S; Planet Y has aliens P and H.
    Once on a planet, they ask one alien for gold; different aliens return coins with varying probabilities which change slowly over trials.

  goal: |
    Your task: Propose **{models_per_iteration} new cognitive models** as Python functions:
    {model_names}

#  instructions: "Participants choose between two spaceships and interact with aliens for rewards."

data:
  max_prompt_trials: 5
  path: "data/two_step_data.csv"
  id_column: "participant"
  input_columns: ["choice_1", "state", "choice_2", "reward"]
  data2text_function: "narrative"

  narrative_template: |
    The participant chose spaceship {choice_1}, traveled to planet {state},
    asked alien {choice_2}, and received {reward} coins.

  value_mappings:
    choice_1:
      "0": "A"
      "1": "U"
    state:
      "0": "X"
      "1": "Y"
    choice_2:
      "0": "W"
      "1": "S"

  splits:
    prompt: "[1:3]"
    eval: "[4:14]"
    test: "[14:]"

llm:
  provider: "qwen"
  base_model: "Qwen/Qwen2-72B-Instruct"
  temperature: 0.2
  max_tokens: 2048
  max_output_tokens: 2048
  system_prompt: |
    You are a renowned cognitive scientist and expert Python programmer.
    You will be given participant data from a two-step decision-making task.
    Your job is to propose cognitive models, expressed as Python functions,
    that explain how participants make their decisions over time.

  models_per_iteration: 3
  include_feedback: true
  guardrails:
    - "Each model must be a standalone Python function."
    - "Function names must be `cognitive_model1`, `cognitive_model2`, etc."
    - "Take as input: `action_1, state, action_2, reward, model_parameters`."
    - "Return the **negative log-likelihood** of observed choices."
    - "Use all parameters meaningfully (no unused params)."
    - "Include a clear docstring for the model and each parameter."
    - "Parameter bounds: [0,1] for most; [0,10] for softmax `beta` (inverse temperature). Please refer to the template for how these are defined."
    - "Do NOT include any package imports inside the code you write. Assume all packages are already imported."

  template_model: |
    def cognitive_model(action_1, state, action_2, reward, model_parameters):
        """Example model illustrating format only (do not reuse logic).
        Bounds:
        learning_rate: [0,1]
        beta: [0,10]
        """
        learning_rate, beta = model_parameters
        n_trials = len(action_1)

        transition_matrix = np.array([[0.7, 0.3], [0.3, 0.7]])
        p_choice_1 = np.zeros(n_trials)
        p_choice_2 = np.zeros(n_trials)
        q_stage1_mf = np.zeros(2)
        q_stage2_mf = np.zeros((2, 2))

        for trial in range(n_trials):
            max_q_stage2 = np.max(q_stage2_mf, axis=1)
            q_stage1_mb = transition_matrix @ max_q_stage2
            exp_q1 = np.exp(beta * q_stage1_mb)
            probs_1 = exp_q1 / np.sum(exp_q1)
            p_choice_1[trial] = probs_1[action_1[trial]]
            state_idx = state[trial]
            exp_q2 = np.exp(beta * q_stage2_mf[state_idx])
            probs_2 = exp_q2 / np.sum(exp_q2)
            p_choice_2[trial] = probs_2[action_2[trial]]
            delta_stage1 = q_stage2_mf[state_idx, action_2[trial]] - q_stage1_mf[action_1[trial]]
            q_stage1_mf[action_1[trial]] += learning_rate * delta_stage1
            delta_stage2 = reward[trial] - q_stage2_mf[state_idx, action_2[trial]]
            q_stage2_mf[state_idx, action_2[trial]] += learning_rate * delta_stage2

        eps = 1e-10
        log_loss = -(np.sum(np.log(p_choice_1 + eps)) + np.sum(np.log(p_choice_2 + eps)))
        return log_loss

evaluation:
  metric: "bic"
  optimizer: "L-BFGS-B"

feedback:
  type: "llm"
