def cognitive_model1(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    RL + capacity-limited working memory (WM) mixture model with age-sensitive WM capacity and decay.
    
    Core idea:
    - Choices arise from a mixture of RL and WM policies.
    - WM has limited capacity; its contribution declines with set size, more gently for younger participants.
    - WM associations decay toward uniform over time; successful rewards refresh the corresponding association.
    - A small lapse rate accounts for random responding and invalid trials are skipped from likelihood.
    
    Parameters (model_parameters):
    - alpha: RL learning rate (0..1)
    - beta: inverse temperature for RL softmax; internally scaled by 10 for dynamic range
    - K: baseline WM capacity (in number of items)
    - phi: WM refresh strength (how strongly a rewarded action overwrites WM) (0..1)
    - w0: baseline WM weight (0..1), before capacity and set-size scaling
    - epsilon: lapse probability (0..1), probability of random choice
    
    Inputs:
    - states: array of state indices per trial (within-block state indices starting at 0)
    - actions: array of chosen action indices per trial (0,1,2). Trials with invalid action (<0 or >=3) are skipped.
    - rewards: array of rewards per trial (0/1). Negative values denote invalid/missed trials and are skipped.
    - blocks: array of block indices per trial
    - set_sizes: array of set size for the block for each trial (3 or 6)
    - age: array-like with a single value, the participant's age
    - model_parameters: tuple/list with parameters in the order specified above
    
    Returns:
    - Negative log-likelihood of the observed choices under the model.
    """
    alpha, beta, K, phi, w0, epsilon = model_parameters
    beta *= 10.0
    age_val = age[0]

    is_older = 1 if age_val >= 45 else 0

    blocks_log_p = 0.0
    for b in np.unique(blocks):
        idx = (blocks == b)
        block_actions = actions[idx]
        block_rewards = rewards[idx]
        block_states = states[idx]
        block_set_sizes = set_sizes[idx]

        nA = 3
        nS = int(block_set_sizes[0])

        Q = (1.0 / nA) * np.ones((nS, nA))
        WM = (1.0 / nA) * np.ones((nS, nA))


        K_eff = max(1.0, K + (1.0 if is_older == 0 else -1.0))

        log_p = 0.0
        for t in range(len(block_states)):
            a = int(block_actions[t])
            s = int(block_states[t])
            r = block_rewards[t]

            invalid = (a < 0) or (a >= nA) or (r < 0)

            Q_s = Q[s, :]

            if not invalid:
                z = Q_s - np.max(Q_s)
                expz = np.exp(beta * z)
                p_rl = expz[a] / np.sum(expz)
            else:
                p_rl = 1.0 / nA  # unused; placeholder

            WM[s, :] = (1.0 - (1.0 - phi) * 0.0) * WM[s, :]  # no per-trial global decay term across all states


            decay_strength = min(1.0, 0.05 * (nS / 3.0))
            WM[s, :] = (1.0 - decay_strength) * WM[s, :] + decay_strength * (1.0 / nA)

            if not invalid:
                p_wm = max(1e-12, WM[s, a])  # ensure numerical stability
            else:
                p_wm = 1.0 / nA  # placeholder


            load_ratio = nS / max(1.0, K_eff)
            wm_weight = w0 * (1.0 / (1.0 + (load_ratio - 1.0) * (2.0 if is_older else 1.0)))
            wm_weight = np.clip(wm_weight, 0.0, 1.0)

            if not invalid:

                p_mix = wm_weight * p_wm + (1.0 - wm_weight) * p_rl
                p_total = (1.0 - epsilon) * p_mix + epsilon * (1.0 / nA)
                log_p += np.log(max(p_total, 1e-12))

                delta = r - Q_s[a]
                Q[s, a] += alpha * delta


                if r > 0:
                    onehot = np.zeros(nA)
                    onehot[a] = 1.0
                    WM[s, :] = (1.0 - phi) * WM[s, :] + phi * onehot
            else:

                continue

        blocks_log_p += log_p

    return -blocks_log_p