def cognitive_model3(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    Asymmetric learning with surprise-dependent decision noise and age-/load-modulated credit spread.

    Idea:
    - Two learning rates for positive and negative prediction errors (PEs).
    - Decision noise (inverse temperature) adapts to surprise: larger unsigned PE -> more noise (lower beta).
    - Credit spreads to non-chosen actions within a state: penalize alternatives when chosen is rewarded,
      or raise alternatives when chosen is unrewarded. Spread magnitude increases with load and in older adults.

    Parameters (model_parameters):
    - alpha_pos: Learning rate for positive PEs in [0,1]
    - alpha_neg: Learning rate for negative PEs in [0,1]
    - beta: Base inverse temperature (>0), internally scaled (x10)
    - spread: Base magnitude of credit spread to non-chosen actions (>=0)
    - load_sens: How much spread increases with set size/load (>=0)
    - age_fac: Additional multiplicative factor on spread for older adults (>=0)

    Inputs:
    - states, actions, rewards, blocks, set_sizes, age: arrays as specified
    - model_parameters: tuple/list with six entries described above

    Returns:
    - Negative log-likelihood of observed choices.
    """
    alpha_pos, alpha_neg, beta, spread, load_sens, age_fac = model_parameters
    alpha_pos = min(max(alpha_pos, 0.0), 1.0)
    alpha_neg = min(max(alpha_neg, 0.0), 1.0)
    beta = max(1e-6, beta) * 10.0
    spread = max(0.0, spread)
    load_sens = max(0.0, load_sens)
    age_fac = max(0.0, age_fac)

    older = 1 if age[0] > 45 else 0
    nA = 3
    eps = 1e-12
    total_loglik = 0.0

    for b in np.unique(blocks):
        idx = (blocks == b)
        block_states = states[idx].astype(int)
        block_actions = actions[idx].astype(int)
        block_rewards = rewards[idx]
        block_set_sizes = set_sizes[idx]

        nS = int(block_set_sizes[0])
        Q = np.zeros((nS, nA))

        for t in range(len(block_states)):
            s = int(block_states[t])
            a = int(block_actions[t])
            r_raw = block_rewards[t]
            if r_raw < 0 or not (0 <= a < nA):

                total_loglik += np.log(1.0 / nA)
                continue

            r = 1.0 if r_raw > 0 else 0.0
            ss = float(block_set_sizes[t])

            pe = r - Q[s, a]
            surprise = abs(pe)
            beta_eff = beta / (1.0 + surprise)  # more surprise -> lower beta (higher noise)

            logits = beta_eff * Q[s, :]
            m = np.max(logits)
            exps = np.exp(logits - m)
            Z = np.sum(exps)
            p = exps[a] / max(Z, eps)
            total_loglik += np.log(max(p, eps))

            if pe >= 0:
                Q[s, a] += alpha_pos * pe
            else:
                Q[s, a] += alpha_neg * pe


            spread_eff = spread * (1.0 + load_sens * ((ss - 3.0) / 3.0)) * (1.0 + age_fac * older)
            if spread_eff > 0:

                others = [aa for aa in range(nA) if aa != a]
                for ao in others:

                    Q[s, ao] -= (spread_eff * pe) / (len(others) if len(others) > 0 else 1.0)

    return -total_loglik