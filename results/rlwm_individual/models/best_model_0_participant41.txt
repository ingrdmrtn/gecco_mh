def cognitive_model1(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    RL+WM capacity-limited mixture with age- and set-size-modulated WM contribution.

    Parameters
    - states: array-like, state index on each trial (0..nS-1 within a block)
    - actions: array-like, chosen action on each trial (0..2; negative values denote omissions/invalid)
    - rewards: array-like, feedback on each trial (0/1; negative values denote missing/invalid)
    - blocks: array-like, block index for each trial
    - set_sizes: array-like, set size (3 or 6) for each trial
    - age: array-like or scalar, participant age (used to assign to older/younger group)
    - model_parameters: list/tuple of parameters:
        alpha: RL learning rate in [0,1]
        beta: inverse temperature for RL policy (scaled internally)
        wm_base: base WM mixture weight (0..1)
        capacity_K: WM capacity (e.g., 1..6), controls set-size effect
        decay: WM decay rate per trial (0..1) toward uniform
        epsilon: lapse rate (0..0.1), adds uniform noise to the final policy

    Returns
    - negative log-likelihood of the observed choices under the model
    """
    alpha, beta, wm_base, capacity_K, decay, epsilon = model_parameters

    beta = max(1e-6, beta) * 10.0
    epsilon = max(0.0, min(0.2, epsilon))
    age_val = age if np.isscalar(age) else age[0]
    is_older = 1.0 if age_val >= 45 else 0.0

    total_logp = 0.0
    unique_blocks = np.unique(blocks)
    nA = 3

    for b in unique_blocks:
        mask = (blocks == b)
        block_actions = actions[mask]
        block_rewards = rewards[mask]
        block_states = states[mask]
        block_set_sizes = set_sizes[mask]
        nS = int(block_set_sizes[0])

        Q = (1.0 / nA) * np.ones((nS, nA))
        W = (1.0 / nA) * np.ones((nS, nA))  # WM policy table (probability-like, row-wise)
        WM_conf = np.zeros(nS)  # confidence/availability of WM for each state (0..1)

        for t in range(len(block_states)):
            a = block_actions[t]
            r = block_rewards[t]
            s = block_states[t]
            ss = block_set_sizes[t]


            K_eff = max(1e-6, capacity_K * (0.7 if is_older > 0.5 else 1.0))
            wm_retrieval = 1.0 / (1.0 + (ss / K_eff))

            wm_weight = wm_base * (1.0 - 0.25 * is_older) * wm_retrieval
            wm_weight = max(0.0, min(1.0, wm_weight))

            Qs = Q[s, :]
            Qs_center = Qs - np.max(Qs)
            p_rl = np.exp(beta * Qs_center)
            p_rl = p_rl / np.sum(p_rl)

            beta_wm = 5.0 * beta
            Ws = W[s, :]
            Ws = np.maximum(Ws, 1e-8)
            Ws = Ws / np.sum(Ws)
            logit_wm = beta_wm * (Ws - np.max(Ws))
            p_wm = np.exp(logit_wm)
            p_wm = p_wm / np.sum(p_wm)


            wm_mix = wm_weight * (0.3 + 0.7 * WM_conf[s])  # ensure some baseline WM contribution
            wm_mix = max(0.0, min(1.0, wm_mix))

            p_mix = wm_mix * p_wm + (1.0 - wm_mix) * p_rl

            p_final = (1.0 - epsilon) * p_mix + epsilon * (1.0 / nA)

            if a >= 0 and r >= 0:
                pa = max(1e-12, min(1.0, p_final[a]))
                total_logp += np.log(pa)

            if a >= 0 and r >= 0:

                delta = r - Q[s, a]
                Q[s, a] += alpha * delta


                if r > 0.5:
                    W[s, :] = (1e-6) * np.ones(nA)
                    W[s, a] = 1.0  # focused WM trace for this state
                    WM_conf[s] = 1.0
                else:

                    W[s, :] = (1.0 - decay) * W[s, :] + decay * (1.0 / nA)
                    WM_conf[s] = (1.0 - decay) * WM_conf[s]
            else:

                if 0 <= s < nS:
                    W[s, :] = (1.0 - decay) * W[s, :] + decay * (1.0 / nA)
                    WM_conf[s] = (1.0 - decay) * WM_conf[s]

    return -total_logp