def cognitive_model2(states, actions, rewards, blocks, set_sizes, model_parameters):
    """
    RL with asymmetric learning rates + WM gated by surprise (prediction error) + lapse.
    
    Idea:
    - RL has separate learning rates for positive vs negative prediction errors.
    - WM's contribution is gated by surprise magnitude (|PE|): higher surprise => stronger WM control.
    - Lapse adds a probability of uniformly random choice.
    
    Parameters
    ----------
    model_parameters : tuple/list of length 6
      lr_pos       : RL learning rate for positive PE (0..1).
      lr_neg       : RL learning rate for negative PE (0..1).
      wm_weight    : Base WM weight (0..1), scaled by surprise magnitude on each trial.
      softmax_beta : RL inverse temperature; internally scaled by 10.
      wm_decay     : WM decay per trial toward uniform (0..1).
      lapse        : Lapse probability of uniform random choice (0..1).
    
    Returns
    -------
    neg_log_likelihood : float
      Negative log-likelihood of the observed action sequence under the model.
    """
    lr_pos, lr_neg, wm_weight, softmax_beta, wm_decay, lapse = model_parameters
    softmax_beta *= 10.0
    softmax_beta_wm = 50.0
    blocks_log_p = 0.0

    for b in np.unique(blocks):
        mask = (blocks == b)
        block_actions = actions[mask]
        block_rewards = rewards[mask]
        block_states  = states[mask]
        block_set_sizes = set_sizes[mask]

        nA = 3
        nS = int(block_set_sizes[0])

        q   = (1.0 / nA) * np.ones((nS, nA))
        w   = (1.0 / nA) * np.ones((nS, nA))
        w_0 = (1.0 / nA) * np.ones((nS, nA))

        log_p = 0.0
        for t in range(len(block_states)):
            a = int(block_actions[t])
            s = int(block_states[t])
            r = float(block_rewards[t])

            logits_rl = softmax_beta * q[s, :]
            max_rl = np.max(logits_rl)
            exp_rl = np.exp(logits_rl - max_rl)
            p_rl_vec = exp_rl / np.sum(exp_rl)
            p_rl = p_rl_vec[a]

            logits_wm = softmax_beta_wm * w[s, :]
            max_wm = np.max(logits_wm)
            exp_wm = np.exp(logits_wm - max_wm)
            p_wm_vec = exp_wm / np.sum(exp_wm)
            p_wm = p_wm_vec[a]

            delta = r - q[s, a]
            surprise = abs(delta)
            wm_mix = np.clip(wm_weight * surprise, 0.0, 1.0)

            p_mix = wm_mix * p_wm + (1.0 - wm_mix) * p_rl
            p_total = (1.0 - lapse) * p_mix + lapse * (1.0 / nA)
            p_total = max(p_total, 1e-12)
            log_p += np.log(p_total)

            lr_eff = lr_pos if delta >= 0.0 else lr_neg
            q[s, a] += lr_eff * delta

            w = (1.0 - wm_decay) * w + wm_decay * w_0

            if r > 0.0:
                one_hot = np.zeros(nA)
                one_hot[a] = 1.0
                w[s, :] = 0.5 * w[s, :] + 0.5 * one_hot
            else:

                reduce = 0.25 * w[s, a]
                w[s, a] -= reduce
                if nA > 1:
                    others = [i for i in range(nA) if i != a]
                    w[s, others] += reduce / (nA - 1)
                row_sum = np.sum(w[s, :])
                if row_sum > 0:
                    w[s, :] /= row_sum
                else:
                    w[s, :] = w_0[s, :].copy()

        blocks_log_p += log_p

    return -blocks_log_p