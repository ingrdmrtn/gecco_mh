def cognitive_model1(states, actions, rewards, blocks, set_sizes, model_parameters):
    """
    RL + WM with load-sensitive WM precision and mixture.

    Mechanism
    - RL: delta-rule Q-learning with softmax (fixed as in template).
    - WM policy: fast softmax over a WM table, but its effective precision and
      mixture weight both depend on set size (load). Below a capacity-like point
      (K50), WM acts more deterministically and is weighted more; above it, WM
      becomes noisier and contributes less.
    - WM update: on each trial, the WM row for the visited state moves toward the
      chosen action's one-hot vector with a rate that also depends on set size in
      the same sigmoidal fashion.

    Parameters
    ----------
    model_parameters : tuple
        (lr, wm_weight, softmax_beta, K50, wm_beta_gain, mix_slope)
        - lr: RL learning rate in [0,1].
        - wm_weight: baseline WM mixture weight in [0,1].
        - softmax_beta: RL inverse temperature (>0); internally scaled by 10.
        - K50: set size at which WM effectiveness is half-max (capacity-like pivot).
        - wm_beta_gain: gain controlling how sharply WM precision scales with load.
        - mix_slope: slope controlling how strongly mixture weight shifts with load.

    Returns
    -------
    float
        Negative log-likelihood of observed choices.
    """
    lr, wm_weight, softmax_beta, K50, wm_beta_gain, mix_slope = model_parameters
    softmax_beta *= 10  # beta has a higher upper bound
    softmax_beta_wm = 50  # very deterministic
    blocks_log_p = 0
    for b in np.unique(blocks):

        block_actions = actions[blocks == b]
        block_rewards = rewards[blocks == b]
        block_states = states[blocks == b]
        block_set_sizes = set_sizes[blocks == b]

        nA = 3
        nS = int(block_set_sizes[0])

        q = (1 / nA) * np.ones((nS, nA))
        w = (1 / nA) * np.ones((nS, nA))
        w_0 = (1 / nA) * np.ones((nS, nA))

        # Load-dependent scalers (fixed within block)
        # Sigmoid load factor: larger for small set sizes (nS << K50)
        load_fac = 1.0 / (1.0 + np.exp(wm_beta_gain * (nS - K50)))
        # Effective WM precision and mixture weight
        beta_wm_eff = softmax_beta_wm * load_fac
        # Map baseline wm_weight in logit space and tilt by load via mix_slope
        eps = 1e-12
        logit = lambda x: np.log(np.clip(x, eps, 1 - eps)) - np.log(np.clip(1 - x, eps, 1 - eps))
        inv_logit = lambda z: 1.0 / (1.0 + np.exp(-z))
        wm_eff_block = inv_logit(logit(wm_weight) + mix_slope * (load_fac - 0.5))

        log_p = 0
        for t in range(len(block_states)):

            a = int(block_actions[t])
            s = int(block_states[t])
            r = float(block_rewards[t])

            Q_s = q[s, :]
            W_s = w[s, :]
            p_rl = 1 / np.sum(np.exp(softmax_beta * (Q_s - Q_s[a])))

            # WM policy: softmax with load-dependent precision
            p_vec_wm = np.exp(beta_wm_eff * (W_s - np.max(W_s)))
            p_vec_wm = p_vec_wm / np.sum(p_vec_wm)
            p_wm = p_vec_wm[a]

            # Mixture using block-level WM effectiveness
            p_total = p_wm * wm_eff_block + (1 - wm_eff_block) * p_rl
            p_total = max(p_total, 1e-12)
            log_p += np.log(p_total)

            # RL update
            delta = r - Q_s[a]
            q[s][a] += lr * delta

            # WM update: move toward one-hot with rate tied to load_fac
            one_hot = np.zeros(nA)
            one_hot[a] = 1.0
            alpha_wm = load_fac  # faster for small set sizes
            w[s, :] = (1.0 - alpha_wm) * w[s, :] + alpha_wm * one_hot

        blocks_log_p += log_p

    return -blocks_log_p


def cognitive_model2(states, actions, rewards, blocks, set_sizes, model_parameters):
    """
    RL + WM with surprise-gated WM encoding and WM leak.

    Mechanism
    - RL: delta-rule Q-learning with softmax (fixed).
    - WM policy: fast softmax over WM.
    - Surprise-gated encoding: The WM update rate on each trial depends on the
      magnitude of the RL prediction error |delta|. More surprising outcomes
      lead to stronger WM encoding.
    - WM leak: Before encoding, the WM row for the visited state leaks toward
      uniform at rate 'leak', modeling rapid forgetting/interference in WM.

    Parameters
    ----------
    model_parameters : tuple
        (lr, wm_weight, softmax_beta, enc_gain, surpr_scale, leak)
        - lr: RL learning rate in [0,1].
        - wm_weight: mixture weight for WM in [0,1].
        - softmax_beta: RL inverse temperature (>0); internally scaled by 10.
        - enc_gain: baseline logit for WM encoding strength.
        - surpr_scale: scales how much |prediction error| boosts encoding.
        - leak: WM leak rate in [0,1] applied to visited state before encoding.

    Returns
    -------
    float
        Negative log-likelihood of observed choices.
    """
    lr, wm_weight, softmax_beta, enc_gain, surpr_scale, leak = model_parameters
    softmax_beta *= 10  # beta has a higher upper bound
    softmax_beta_wm = 50  # very deterministic
    blocks_log_p = 0
    for b in np.unique(blocks):

        block_actions = actions[blocks == b]
        block_rewards = rewards[blocks == b]
        block_states = states[blocks == b]
        block_set_sizes = set_sizes[blocks == b]

        nA = 3
        nS = int(block_set_sizes[0])

        q = (1 / nA) * np.ones((nS, nA))
        w = (1 / nA) * np.ones((nS, nA))
        w_0 = (1 / nA) * np.ones((nS, nA))

        log_p = 0
        for t in range(len(block_states)):

            a = int(block_actions[t])
            s = int(block_states[t])
            r = float(block_rewards[t])

            Q_s = q[s, :]
            W_s = w[s, :]
            p_rl = 1 / np.sum(np.exp(softmax_beta * (Q_s - Q_s[a])))

            # WM policy: standard high-precision softmax
            p_vec_wm = np.exp(softmax_beta_wm * (W_s - np.max(W_s)))
            p_vec_wm = p_vec_wm / np.sum(p_vec_wm)
            p_wm = p_vec_wm[a]

            p_total = p_wm * wm_weight + (1 - wm_weight) * p_rl
            p_total = max(p_total, 1e-12)
            log_p += np.log(p_total)

            # RL update
            delta = r - Q_s[a]
            q[s][a] += lr * delta

            # WM update:
            # 1) Leak visited state's WM toward uniform
            w[s, :] = (1.0 - leak) * w[s, :] + leak * w_0[s, :]

            # 2) Surprise-gated encoding toward chosen action
            pe_mag = abs(delta)
            # Encoding rate in (0,1) via logistic of (enc_gain + surpr_scale*|PE|)
            alpha_enc = 1.0 / (1.0 + np.exp(-(enc_gain + surpr_scale * pe_mag)))
            one_hot = np.zeros(nA)
            one_hot[a] = 1.0
            w[s, :] = (1.0 - alpha_enc) * w[s, :] + alpha_enc * one_hot

        blocks_log_p += log_p

    return -blocks_log_p


def cognitive_model3(states, actions, rewards, blocks, set_sizes, model_parameters):
    """
    RL + WM with load-induced cross-state interference and WM-driven mixture suppression.

    Mechanism
    - RL: delta-rule Q-learning with softmax (fixed).
    - WM cross-talk: Under higher load (larger set size), the WM representation
      for the current state is contaminated by the average of other states'
      WM rows. A load-dependent factor determines the strength of this cross-talk.
    - Mixture suppression: The effective WM mixture weight is reduced in
      proportion to the cross-talk (i.e., when WM is more confused, rely more on RL).
    - WM policy: softmax over the contaminated WM representation with an
      adjustable precision scaling.
    - WM update: Hebbian-like push toward the chosen action; the step size is a
      smooth function of the WM precision scale to tie memory strength to policy certainty.

    Parameters
    ----------
    model_parameters : tuple
        (lr, wm_weight, softmax_beta, cross_talk, load_bias, beta_wm_scale)
        - lr: RL learning rate in [0,1].
        - wm_weight: baseline mixture weight in [0,1].
        - softmax_beta: RL inverse temperature (>0); internally scaled by 10.
        - cross_talk: maximal cross-state interference factor in [0,1].
        - load_bias: slope controlling how interference grows with set size.
        - beta_wm_scale: scales WM policy precision (>0) relative to default.

    Returns
    -------
    float
        Negative log-likelihood of observed choices.
    """
    lr, wm_weight, softmax_beta, cross_talk, load_bias, beta_wm_scale = model_parameters
    softmax_beta *= 10  # beta has a higher upper bound
    softmax_beta_wm = 50  # very deterministic
    blocks_log_p = 0
    for b in np.unique(blocks):

        block_actions = actions[blocks == b]
        block_rewards = rewards[blocks == b]
        block_states = states[blocks == b]
        block_set_sizes = set_sizes[blocks == b]

        nA = 3
        nS = int(block_set_sizes[0])

        q = (1 / nA) * np.ones((nS, nA))
        w = (1 / nA) * np.ones((nS, nA))
        w_0 = (1 / nA) * np.ones((nS, nA))

        # Load-dependent cross-talk factor (0..cross_talk)
        # Increases with set size relative to a low-load reference (3)
        load_term = 1.0 / (1.0 + np.exp(-load_bias * (nS - 3)))
        ct = np.clip(cross_talk * load_term, 0.0, 1.0)
        beta_wm_eff = softmax_beta_wm * max(beta_wm_scale, 1e-6)

        log_p = 0
        for t in range(len(block_states)):

            a = int(block_actions[t])
            s = int(block_states[t])
            r = float(block_rewards[t])

            Q_s = q[s, :]
            # Build contaminated WM representation for current state
            if nS > 1:
                others = [i for i in range(nS) if i != s]
                mean_others = np.mean(w[others, :], axis=0)
            else:
                mean_others = w[s, :]

            W_s_clean = w[s, :]
            W_s = (1.0 - ct) * W_s_clean + ct * mean_others

            p_rl = 1 / np.sum(np.exp(softmax_beta * (Q_s - Q_s[a])))

            # WM policy over contaminated representation
            p_vec_wm = np.exp(beta_wm_eff * (W_s - np.max(W_s)))
            p_vec_wm = p_vec_wm / np.sum(p_vec_wm)
            p_wm = p_vec_wm[a]

            # Mixture suppression proportional to cross-talk
            wm_eff = wm_weight * (1.0 - ct)

            p_total = p_wm * wm_eff + (1 - wm_eff) * p_rl
            p_total = max(p_total, 1e-12)
            log_p += np.log(p_total)

            # RL update
            delta = r - Q_s[a]
            q[s][a] += lr * delta

            # WM update on clean store: Hebbian push toward chosen action
            one_hot = np.zeros(nA)
            one_hot[a] = 1.0
            # Step size tied to WM precision scale (bounded in 0..1)
            alpha_wm = 1.0 - np.exp(-beta_wm_scale)
            w[s, :] = (1.0 - alpha_wm) * w[s, :] + alpha_wm * one_hot

        blocks_log_p += log_p

    return -blocks_log_p