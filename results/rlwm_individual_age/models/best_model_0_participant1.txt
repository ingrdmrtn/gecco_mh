def cognitive_model1(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    RL+WM mixture with decay and load-/age-dependent arbitration.

    Idea:
    - Choices are a mixture of an incremental RL system and a fast-decaying working-memory (WM) system.
    - WM contributes more when load is low (set size=3) and for younger adults; it contributes less under high load (set size=6) and for older adults.
    - WM stores the last rewarded action for each state with probabilistic encoding and global decay to a uniform prior.
    - A small lapse rate ensures numerical stability and captures occasional lapses.

    Parameters (model_parameters):
    - lr: scalar in (0,1), RL learning rate.
    - wm_weight: base mixture weight for WM (0..1) before age/load modulation.
    - softmax_beta: inverse temperature for RL softmax; internally scaled by 10.
    - wm_decay: (optional) global decay rate toward the uniform WM prior per trial (0..1). Default 0.1 if not provided.
    - wm_eta: (optional) encoding strength for WM updates on rewarded trials (0..1). Default 0.9 if not provided.
    - lapse: (optional) lapse probability mixing with uniform (0..0.1). Default 1e-6 if not provided.

    Inputs:
    - states, actions, rewards: arrays of equal length with integer states (0..nS-1), actions (0..2), rewards (0/1).
    - blocks: array of block indices matching trials.
    - set_sizes: array of set size per trial (3 or 6).
    - age: array-like; age[0] is used. Younger: <45; Older: >=45.

    Returns:
    - Negative log-likelihood of observed choices.
    """

    if len(model_parameters) == 3:
        lr, wm_weight, softmax_beta = model_parameters
        wm_decay = 0.1
        wm_eta = 0.9
        lapse = 1e-6
    elif len(model_parameters) == 4:
        lr, wm_weight, softmax_beta, wm_decay = model_parameters
        wm_eta = 0.9
        lapse = 1e-6
    elif len(model_parameters) == 5:
        lr, wm_weight, softmax_beta, wm_decay, wm_eta = model_parameters
        lapse = 1e-6
    else:
        lr, wm_weight, softmax_beta, wm_decay, wm_eta, lapse = model_parameters

    softmax_beta *= 10  # increase RL beta scale
    softmax_beta_wm = 50  # near-deterministic WM
    age = age[0]

    age_factor = 1.0 if age < 45 else 0.7

    blocks_log_p = 0.0
    for b in np.unique(blocks):
        block_idx = (blocks == b)
        block_actions = actions[block_idx]
        block_rewards = rewards[block_idx]
        block_states = states[block_idx]
        block_set_sizes = set_sizes[block_idx]

        nA = 3
        nS = int(block_set_sizes[0])  # set size constant within block

        q = (1.0 / nA) * np.ones((nS, nA))
        w = (1.0 / nA) * np.ones((nS, nA))
        w_0 = (1.0 / nA) * np.ones((nS, nA))

        log_p = 0.0
        for t in range(len(block_states)):
            a = block_actions[t]
            s = block_states[t]
            r = block_rewards[t]

            Q_s = q[s, :]
            p_rl = 1.0 / np.sum(np.exp(softmax_beta * (Q_s - Q_s[a])))

            W_s = w[s, :]
            p_wm = 1.0 / np.sum(np.exp(softmax_beta_wm * (W_s - W_s[a])))

            load_factor = min(1.0, 3.0 / float(nS))  # 1.0 at set size 3; 0.5 at set size 6
            wm_w_eff = wm_weight * age_factor * load_factor

            p_mix = wm_w_eff * p_wm + (1.0 - wm_w_eff) * p_rl
            p_total = (1.0 - lapse) * p_mix + lapse * (1.0 / nA)
            p_total = max(p_total, 1e-12)
            log_p += np.log(p_total)

            delta = r - Q_s[a]
            q[s, a] += lr * delta

            w = (1.0 - wm_decay) * w + wm_decay * w_0

            if r == 1:
                onehot = np.zeros(nA)
                onehot[a] = 1.0
                w[s, :] = (1.0 - wm_eta) * w[s, :] + wm_eta * onehot
            else:

                w[s, :] = (1.0 - 0.5 * wm_eta) * w[s, :] + 0.5 * wm_eta * w_0[s, :]

        blocks_log_p += log_p

    return -blocks_log_p