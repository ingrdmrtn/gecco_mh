def cognitive_model2(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    RL+WM with reward-gated WM encoding and set size/age-dependent WM engagement.

    Idea:
    - WM is engaged with a probability that decreases with set size and (slightly) with age.
    - WM encodes only after rewarded trials; otherwise it simply decays toward uniform.
    - WM policy is high-precision but its actual contribution is scaled on each trial by the engagement gate.

    Parameters (model_parameters):
    - lr: RL learning rate (0..1).
    - wm_weight: Baseline WM weight (0..1).
    - softmax_beta: RL inverse temperature (scaled internally).
    - gate: Baseline WM engagement factor (0..1) that is further scaled by set size and age.
    - beta_wm_base: Base WM inverse temperature prior to set size/age scaling.
    - decay: WM decay rate toward uniform (0..1).

    Inputs:
    - states, actions, rewards, blocks, set_sizes, age

    Returns:
    - Negative log-likelihood of observed choices.
    """
    lr, wm_weight, softmax_beta, gate, beta_wm_base, decay = model_parameters
    softmax_beta *= 10.0
    age_val = age
    younger = 1 if age_val < 45 else 0

    eps = 1e-12
    blocks_log_p = 0.0

    for b in np.unique(blocks):
        mask = (blocks == b)
        block_actions = actions[mask]
        block_rewards = rewards[mask]
        block_states = states[mask]
        block_set_sizes = set_sizes[mask]

        nA = 3
        nS = int(block_set_sizes[0])

        q = (1.0 / nA) * np.ones((nS, nA))
        w = (1.0 / nA) * np.ones((nS, nA))
        w_0 = (1.0 / nA) * np.ones((nS, nA))

        log_p = 0.0
        for t in range(len(block_states)):
            a = int(block_actions[t])
            s = int(block_states[t])
            r = float(block_rewards[t])

            Q_s = q[s, :]
            W_s = w[s, :]

            p_rl = 1.0 / np.sum(np.exp(softmax_beta * (Q_s - Q_s[a])))

            size_scale = 3.0 / max(1.0, float(nS))  # lower precision at larger set sizes
            age_scale = 1.0 if younger == 1 else 0.7
            softmax_beta_wm = beta_wm_base * size_scale * age_scale

            p_wm = 1.0 / np.sum(np.exp(softmax_beta_wm * (W_s - W_s[a])))

            gate_eff = np.clip(wm_weight * gate * size_scale * (1.0 if younger == 1 else 0.85), 0.0, 1.0)

            p_total = gate_eff * p_wm + (1.0 - gate_eff) * p_rl
            p_total = np.clip(p_total, eps, 1.0)
            log_p += np.log(p_total)

            delta = r - Q_s[a]
            q[s, a] += lr * delta


            w[s, :] = (1.0 - decay) * w[s, :] + decay * w_0[s, :]

            if r > 0.5:
                onehot = np.zeros(nA)
                onehot[a] = 1.0

                w[s, :] = (1.0 - decay) * w[s, :] + decay * onehot

        blocks_log_p += log_p

    return -blocks_log_p