def cognitive_model1(states, actions, rewards, blocks, set_sizes, age, model_parameters):
    """
    RL+WM mixture with capacity-limited working memory and age-related capacity penalty.
    - RL: standard delta rule with softmax policy.
    - WM: one-shot learning with decay toward uniform. If rewarded, store near one-hot for chosen action;
      if not rewarded, suppress chosen action slightly.
    - Mixture: WM contribution scales with an effective capacity term that depends on set size and age group.

    Parameters (tuple):
      lr:                RL learning rate (also used as WM learning strength)
      wm_weight:         Base WM mixture weight in [0,1]
      softmax_beta:      RL inverse temperature (will be scaled by 10 internally)
      K:                 WM capacity (in "items" units)
      decay:             WM decay toward uniform per trial (0=none, 1=full reset)
      age_penalty:       Capacity penalty applied if participant is older (>=45): K_eff = K - age_penalty

    Returns:
      Negative log-likelihood of observed choices.
    """
    lr, wm_weight, softmax_beta, K, decay, age_penalty = model_parameters
    softmax_beta *= 10.0
    softmax_beta_wm = 50.0
    age_val = age[0]
    older = 1.0 if age_val >= 45 else 0.0

    eps = 1e-12
    blocks_log_p = 0.0

    for b in np.unique(blocks):

        block_mask = (blocks == b)
        block_actions = actions[block_mask]
        block_rewards = rewards[block_mask]
        block_states = states[block_mask]
        block_set_sizes = set_sizes[block_mask]

        nA = 3
        nS = int(block_set_sizes[0])

        q = (1.0 / nA) * np.ones((nS, nA))
        w = (1.0 / nA) * np.ones((nS, nA))
        w_0 = (1.0 / nA) * np.ones((nS, nA))

        K_eff = max(0.0, K - age_penalty * older)

        log_p = 0.0
        for t in range(len(block_states)):

            a = int(block_actions[t])
            s = int(block_states[t])
            r = float(block_rewards[t])

            Q_s = q[s, :]
            Q_center = Q_s[a]
            p_rl = 1.0 / np.sum(np.exp(softmax_beta * (Q_s - Q_center)))


            w[s, :] = (1.0 - decay) * w[s, :] + decay * w_0[s, :]

            W_s = w[s, :]
            W_center = W_s[a]
            p_wm = 1.0 / np.sum(np.exp(softmax_beta_wm * (W_s - W_center)))

            load_factor = 0.0 if nS <= 0 else min(1.0, K_eff / float(nS))
            eta = np.clip(wm_weight * load_factor, 0.0, 1.0)

            p_total = eta * p_wm + (1.0 - eta) * p_rl
            log_p += np.log(max(p_total, eps))

            delta = r - Q_s[a]
            q[s, a] += lr * delta

            if r > 0.5:

                target = np.zeros(nA)
                target[a] = 1.0
                w[s, :] = (1.0 - lr) * w[s, :] + lr * target
            else:

                w[s, a] = max(eps, w[s, a] * (1.0 - lr))

                w_sum = np.sum(w[s, :])
                if w_sum > 0:
                    w[s, :] /= w_sum
                else:
                    w[s, :] = w_0[s, :]

        blocks_log_p += log_p

    return -blocks_log_p