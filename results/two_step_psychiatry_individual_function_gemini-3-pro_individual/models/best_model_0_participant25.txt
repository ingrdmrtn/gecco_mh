def cognitive_model2(action_1, state, action_2, reward, model_parameters):
    """
    Reinforcement Learning with Choice Kernel (Perseveration).
    Tracks value (RL) and a choice trace (CK) to bias repetition.
    
    Parameters:
    learning_rate: [0, 1] - Update rate for Q-values.
    beta: [0, 10] - Inverse temperature for value-based choice.
    ck_learning_rate: [0, 1] - Decay rate for the choice trace.
    beta_k: [0, 10] - Strength of perseveration (positive) or alternation (negative).
    """
    learning_rate, beta, ck_learning_rate, beta_k = model_parameters
    n_trials = len(action_1)
    
    q_stage1 = np.zeros(2)
    q_stage2 = np.zeros((2, 2))

    ck_stage1 = np.zeros(2)
    ck_stage2 = np.zeros((2, 2))
    
    p_choice_1 = np.zeros(n_trials)
    p_choice_2 = np.zeros(n_trials)

    for trial in range(n_trials):




        logits_1 = (beta * q_stage1) + (beta_k * ck_stage1)

        exp_1 = np.exp(logits_1 - np.max(logits_1))
        probs_1 = exp_1 / np.sum(exp_1)
        p_choice_1[trial] = probs_1[action_1[trial]]
        
        state_idx = state[trial]

        logits_2 = (beta * q_stage2[state_idx]) + (beta_k * ck_stage2[state_idx])
        exp_2 = np.exp(logits_2 - np.max(logits_2))
        probs_2 = exp_2 / np.sum(exp_2)
        p_choice_2[trial] = probs_2[action_2[trial]]



        ck_stage1 *= (1 - ck_learning_rate)
        ck_stage2[state_idx] *= (1 - ck_learning_rate)

        ck_stage1[action_1[trial]] += 1 * ck_learning_rate
        ck_stage2[state_idx, action_2[trial]] += 1 * ck_learning_rate

        delta_stage1 = q_stage2[state_idx, action_2[trial]] - q_stage1[action_1[trial]]
        q_stage1[action_1[trial]] += learning_rate * delta_stage1
        
        delta_stage2 = reward[trial] - q_stage2[state_idx, action_2[trial]]
        q_stage2[state_idx, action_2[trial]] += learning_rate * delta_stage2

        q_stage1[action_1[trial]] += learning_rate * delta_stage2

    eps = 1e-10
    log_loss = -(np.sum(np.log(p_choice_1 + eps)) + np.sum(np.log(p_choice_2 + eps)))
    return log_loss

import numpy as np