def cognitive_model3(action_1, state, action_2, reward, model_parameters):
    """
    Independent MB/MF Betas Model.
    
    Replaces the mixing parameter 'w' and shared 'beta' with independent 
    scaling factors (betas) for the Model-Based and Model-Free components.
    This allows for independent strength/precision of each system.
    
    Parameters:
    learning_rate: [0, 1] - Learning rate for Q-value updates.
    beta_mb: [0, 10] - Scaling factor (inverse temp) for Model-Based values in Stage 1.
    beta_mf: [0, 10] - Scaling factor (inverse temp) for Model-Free values (Stage 1 & 2).
    stickiness: [0, 5] - Bonus added to the Q-value of the previously chosen action.
    """
    learning_rate, beta_mb, beta_mf, stickiness = model_parameters
    n_trials = len(action_1)

    transition_matrix = np.array([[0.7, 0.3], [0.3, 0.7]])
    
    q_mf_stage1 = np.zeros(2)
    q_mf_stage2 = np.zeros((2, 2)) 
    
    last_action_1 = -1
    log_loss = 0.0
    eps = 1e-10
    
    for trial in range(n_trials):
        a1 = action_1[trial]
        s_idx = state[trial]
        a2 = action_2[trial]
        r = reward[trial]

        max_q_stage2 = np.max(q_mf_stage2, axis=1)
        q_mb_stage1 = transition_matrix @ max_q_stage2


        logits_stage1 = (beta_mb * q_mb_stage1) + (beta_mf * q_mf_stage1)

        if last_action_1 != -1:
            logits_stage1[last_action_1] += stickiness

        exp_q1 = np.exp(logits_stage1)
        probs_1 = exp_q1 / np.sum(exp_q1)
        
        if a1 != -1:
            log_loss -= np.log(probs_1[a1] + eps)


        logits_stage2 = beta_mf * q_mf_stage2[s_idx]
        
        exp_q2 = np.exp(logits_stage2)
        probs_2 = exp_q2 / np.sum(exp_q2)
        
        if a2 != -1:
            log_loss -= np.log(probs_2[a2] + eps)

            delta_2 = r - q_mf_stage2[s_idx, a2]
            q_mf_stage2[s_idx, a2] += learning_rate * delta_2

            q_mf_stage1[a1] += learning_rate * (r - q_mf_stage1[a1])
            
        last_action_1 = a1

    return log_loss