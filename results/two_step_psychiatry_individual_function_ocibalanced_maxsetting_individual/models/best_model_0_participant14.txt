def cognitive_model2(action_1, state, action_2, reward, model_parameters):
    """
    Hybrid MB/MF model with Asymmetric Learning Rates and Stickiness.
    
    Differentiates between learning from positive prediction errors (wins/better than expected)
    and negative prediction errors (losses/worse than expected).

    Parameters:
    - lr_pos: [0, 1] Learning rate for positive prediction errors.
    - lr_neg: [0, 1] Learning rate for negative prediction errors.
    - beta: [0, 10] Inverse temperature.
    - w: [0, 1] Weight of Model-Based system.
    - lam: [0, 1] Eligibility trace.
    - stickiness: [0, 5] Choice perseveration bonus.
    """
    lr_pos, lr_neg, beta, w, lam, stickiness = model_parameters
    n_trials = len(action_1)

    transition_matrix = np.array([[0.7, 0.3], [0.3, 0.7]])

    q_mf = np.zeros(2)         
    q2 = np.zeros((2, 2))      
    
    p_choice_1 = np.zeros(n_trials)
    p_choice_2 = np.zeros(n_trials)
    
    last_action_1 = -1
    eps = 1e-10

    for trial in range(n_trials):
        a1 = int(action_1[trial])
        s = int(state[trial])
        a2 = int(action_2[trial])
        r = int(reward[trial])

        if a1 == -1:
            continue

        max_q2 = np.max(q2, axis=1)
        q_mb = transition_matrix @ max_q2
        q_net = w * q_mb + (1 - w) * q_mf

        if last_action_1 != -1:
            q_net[last_action_1] += stickiness

        exp_q1 = np.exp(beta * q_net)
        probs_1 = exp_q1 / np.sum(exp_q1)
        p_choice_1[trial] = probs_1[a1]

        exp_q2 = np.exp(beta * q2[s])
        probs_2 = exp_q2 / np.sum(exp_q2)
        p_choice_2[trial] = probs_2[a2]


        delta_1 = q2[s, a2] - q_mf[a1]
        lr_1 = lr_pos if delta_1 > 0 else lr_neg
        q_mf[a1] += lr_1 * delta_1

        delta_2 = r - q2[s, a2]
        lr_2 = lr_pos if delta_2 > 0 else lr_neg
        q2[s, a2] += lr_2 * delta_2


        q_mf[a1] += lr_2 * lam * delta_2

        last_action_1 = a1

    mask = p_choice_1 > 0
    log_loss = -(np.sum(np.log(p_choice_1[mask] + eps)) + np.sum(np.log(p_choice_2[mask] + eps)))
    return log_loss