def cognitive_model3(action_1, state, action_2, reward, model_parameters):
    """
    Stage-Specific Stickiness Model-Free Q-Learning.
    
    This model incorporates stickiness (perseveration) for both Stage 1 and 
    Stage 2 choices independently. The participant data suggests habits form 
    not just for the spaceship (Stage 1) but also for specific aliens at each 
    planet (Stage 2). This model allows quantifying these two distinct forms 
    of perseveration.
    
    Parameters:
    learning_rate: [0, 1] Learning rate.
    beta:          [0, 10] Inverse temperature.
    stick_s1:      [-5, 5] Stickiness for Stage 1 (Spaceship).
    stick_s2:      [-5, 5] Stickiness for Stage 2 (Alien).
    """
    learning_rate, beta, stick_s1, stick_s2 = model_parameters
    n_trials = len(action_1)
    
    q_stage1 = np.zeros(2) + 0.5
    q_stage2 = np.zeros((2, 2)) + 0.5
    
    log_loss = 0
    eps = 1e-10
    
    prev_action_1 = -1
    prev_action_2 = np.array([-1, -1]) # Track last choice for each state (Planet 0, Planet 1)
    
    for trial in range(n_trials):
        a1 = action_1[trial]
        s_idx = state[trial]
        a2 = action_2[trial]
        r = reward[trial]

        logits_1 = beta * q_stage1
        if prev_action_1 != -1:
            logits_1[prev_action_1] += stick_s1
            
        exp_q1 = np.exp(logits_1 - np.max(logits_1))
        probs_1 = exp_q1 / np.sum(exp_q1)
        log_loss -= np.log(probs_1[a1] + eps)

        logits_2 = beta * q_stage2[s_idx]

        if prev_action_2[s_idx] != -1:
            logits_2[prev_action_2[s_idx]] += stick_s2
            
        exp_q2 = np.exp(logits_2 - np.max(logits_2))
        probs_2 = exp_q2 / np.sum(exp_q2)
        log_loss -= np.log(probs_2[a2] + eps)

        target_stage1 = q_stage2[s_idx, a2]
        q_stage1[a1] += learning_rate * (target_stage1 - q_stage1[a1])
        
        q_stage2[s_idx, a2] += learning_rate * (r - q_stage2[s_idx, a2])
        
        prev_action_1 = a1
        prev_action_2[s_idx] = a2
        
    return log_loss