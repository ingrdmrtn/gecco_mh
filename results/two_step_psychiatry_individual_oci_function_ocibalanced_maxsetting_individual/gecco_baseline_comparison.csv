participant,fitted_parameters,parsed_params,num_params,extraction_mismatch,shared_params,unique_params,shared_mechanisms,unique_mechanisms,psychiatry_mediated_mechanisms,psychiatry_mediated_parameters,shared,model_type,baseline_params,baseline_bic,best_model_bic,oci
14,"[np.float64(1.0), np.float64(0.4349952334407714), np.float64(-0.118842258372887), np.float64(1.7565203384433667), np.float64(0.7471541850517207), np.float64(0.594098363778181)]",['lr_pos' 'lr_neg_base' 'lr_neg_oci' 'beta' 'w' 'stickiness'],6,False,"['beta', 'w', 'perseveration']","['lr_pos', 'lr_neg_base', 'lr_neg_oci']","['model-based-mixing', 'choice-perseveration', 'eligibility-traces']","['asymmetric-learning-rates', 'oci-modulated-learning']",['oci-modulated-learning'],['lr_neg_oci'],partial,OCI-Modulated Asymmetric Learning Rate Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",516.9225775710403,495.6763978477013,0.3
15,"[np.float64(0.0872943347590243), np.float64(6.5917978372576025), np.float64(1.4300021727243897), np.float64(2.446127299520893), np.float64(1.0), np.float64(0.3936714150269601)]",['lr' 'beta_common' 'beta_rare_base' 'beta_rare_oci_mod' 'w' 'stickiness'],6,False,"['learning_rate', 'beta', 'w', 'perseveration']","['beta_rare_base', 'beta_rare_oci_mod']","['hybrid-learning', 'choice-perseveration', 'eligibility-traces']",['surprise-dependent-precision'],['oci-modulated-precision'],['beta_rare_oci_mod'],partial,Surprise-Dependent Stage 2 Precision Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",350.1519827210901,325.6433690178796,0.35
16,"[np.float64(0.7213696245364691), np.float64(1.2879031981973827), np.float64(0.0), np.float64(0.8608365373701145), np.float64(1.075712489443036), np.float64(1.6220435052713538)]",['lr' 'beta_base' 'w' 'stickiness' 'conf_sens_low' 'conf_sens_high'],6,False,"['learning_rate', 'beta', 'w', 'perseveration']","['conf_sens_low', 'conf_sens_high']","['model-based-learning', 'model-free-learning', 'choice-perseveration']",['confidence-modulated-beta'],['confidence-modulation-sensitivity'],"['conf_sens_low', 'conf_sens_high']",partial,Confidence-Modulated Beta Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",448.29091589139017,432.91221974150955,0.6166666666666667
17,"[np.float64(0.6002809427216355), np.float64(3.7755728928309167), np.float64(1.0), np.float64(0.5560686333829878), np.float64(-0.0832939846457239), np.float64(1.2445047387476076)]",['learning_rate' 'beta' 'w_init' 'w_decay_base' 'w_decay_oci' 'stickiness'],6,False,"['learning_rate', 'beta', 'w', 'perseveration']","['w_decay_base', 'w_decay_oci']","['model-based-learning', 'model-free-learning', 'hybrid-value-estimation', 'choice-perseveration', 'eligibility-traces']",['dynamic-weight-decay'],['oci-modulated-decay'],['w_decay_oci'],partial,Model with Dynamic Model-Based Weight Decay Modulated by OCI,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",358.76648668733304,352.3767367922505,0.4
18,"[np.float64(1.0), np.float64(1.625600573024425), np.float64(0.1726727409541626), np.float64(1.0), np.float64(0.8360159394156622), np.float64(1.0)]",['lr' 'beta' 'w' 'lambda_val' 'stickiness' 'decay_rate'],6,False,"['learning_rate', 'beta', 'w', 'lambd', 'perseveration']",['decay_rate'],"['model-based-learning', 'model-free-learning', 'eligibility-traces', 'choice-perseveration']",['unchosen-value-decay'],['unchosen-value-decay'],['decay_rate'],partial,OCI-Modulated Memory Decay (Doubt Hypothesis),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",465.0871657985018,446.43773697298536,0.45
19,"[np.float64(0.521743032045502), np.float64(2.439193513649609), np.float64(0.8633295382941479), np.float64(1.3065231856713757)]",['learning_rate' 'beta' 'w' 'reinf_stick'],4,False,"['learning_rate', 'beta', 'w']",['reinf_stick'],"['model-based-learning', 'model-free-learning', 'hybrid-value-estimation']",['reinforced-stickiness'],['reinforced-stickiness'],['reinf_stick'],partial,OCI-Modulated Reinforced Stickiness,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",454.2144083137601,438.0938636511702,0.6
20,"[np.float64(0.8478777329386258), np.float64(9.311030706222182), np.float64(0.853016030961348), np.float64(0.8875887614329534), np.float64(0.7654316627906648)]",['lr' 'beta' 'w' 'stick' 'rare_gating_oci'],5,False,"['learning_rate', 'beta', 'w', 'perseveration']",['rare_gating_oci'],"['model-based-model-free-hybrid', 'softmax-action-selection', 'perseveration', 'temporal-difference-learning']",[],['OCI-modulated-learning-gating'],['rare_gating_oci'],partial,OCI-Modulated Gating of Learning from Rare Transitions,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",362.1901046298327,271.3574735831389,0.3666666666666666
21,"[np.float64(0.5861262560930232), np.float64(4.008811748540581), np.float64(0.6947229251620569), np.float64(1.1306801952841112), np.float64(0.5382426292954642), np.float64(-0.9525800865349572)]",['lr' 'beta' 'w' 'pers_static' 'pers_accum_base' 'pers_accum_oci'],6,False,"['learning_rate', 'beta', 'w', 'perseveration']","['pers_accum_base', 'pers_accum_oci']","['model-free-learning', 'model-based-learning', 'hybrid-value-estimation', 'static-perseveration']",['accumulated-stickiness'],['oci-modulated-accumulation'],['pers_accum_oci'],partial,Dynamic Perseveration Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",288.53968578957466,268.1427274928878,0.6166666666666667
22,"[np.float64(0.1605676822237429), np.float64(0.9846278404561244), np.float64(-0.1580042874039295), np.float64(10.0), np.float64(0.9834212996578536), np.float64(0.1940707589056653)]",['lr_pos' 'lr_neg_base' 'lr_neg_oci_slope' 'beta' 'w' 'stickiness'],6,False,"['beta', 'w', 'perseveration']","['lr_pos', 'lr_neg_base', 'lr_neg_oci_slope']","['model-based-learning', 'choice-perseverance']",['valence-dependent-learning'],['oci-modulated-learning'],['lr_neg_oci_slope'],partial,OCI-Modulated Asymmetric Learning Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",373.1977620978524,333.89848241235757,0.6
23,"[np.float64(0.4124053764265377), np.float64(5.277222503056821), np.float64(0.301499704867906), np.float64(2.1241302828156816), np.float64(0.5994945239379426), np.float64(-0.246817565081039)]",['learning_rate' 'beta' 'w' 'stickiness' 'decay_base' 'decay_oci'],6,False,"['learning_rate', 'beta', 'w', 'perseveration']","['decay_base', 'decay_oci']","['model-based-learning', 'model-free-learning', 'choice-perseveration']",['outcome-value-decay'],['outcome-value-decay'],['decay_oci'],partial,OCI-Modulated Outcome Value Decay,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",374.5861601736647,344.56900470773326,0.3666666666666666
24,"[np.float64(0.6884110315189597), np.float64(0.7988504741173815), np.float64(1.0), np.float64(0.6005075247176875), np.float64(-0.363244934892656)]",['learning_rate' 'beta' 'w' 'persev_base' 'losestay_oci_slope'],5,False,"['learning_rate', 'beta', 'w', 'perseveration']",['losestay_oci_slope'],"['hybrid-learning', 'model-free-learning', 'softmax-action-selection', 'choice-perseveration']",['oci-modulated-lose-stay'],['oci-modulated-lose-stay'],['losestay_oci_slope'],partial,Hybrid MB/MF model where OCI modulates 'Lose-Stay' behavior,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",572.5972640584621,526.7661699639465,0.5166666666666667
25,"[np.float64(0.5910151177359034), np.float64(0.0), np.float64(3.35701443127725), np.float64(1.4056338067581764), np.float64(-0.1626183867062201)]",['learning_rate' 'w' 'beta_win' 'beta_loss_base' 'beta_loss_oci'],5,False,"['learning_rate', 'w']","['beta_win', 'beta_loss_base', 'beta_loss_oci']","['hybrid-learning', 'eligibility-traces']",['outcome-dependent-noise'],['oci-modulated-noise'],['beta_loss_oci'],partial,OCI-Modulated Inverse Temperature Asymmetry (Win vs Loss),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",468.7032695600562,459.93575706328215,0.3833333333333333
26,"[np.float64(0.6040105559561437), np.float64(0.7912823293806805), np.float64(1.0)]",['lr_base' 'beta' 'w'],3,False,"['beta', 'w']",['lr_base'],"['hybrid-value-estimation', 'softmax-action-selection', 'temporal-difference-learning']",['oci-modulated-plasticity'],['oci-modulated-plasticity'],['lr_base'],partial,Hybrid Model with OCI-Modulated Plasticity (Learning Rate),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",581.4052370598846,550.4625150559918,0.55
27,"[np.float64(0.3119342368236041), np.float64(0.0270345592248146), np.float64(5.759513965045437), np.float64(0.3733412287184386), np.float64(0.2552220420222878)]",['lr_s1' 'lr_s2' 'beta' 'w' 'stickiness_base'],5,False,"['learning_rate', 'learning_rate_2', 'beta', 'w']",['stickiness_base'],"['model-based-learning', 'model-free-learning', 'perseveration-bias', 'eligibility-traces']",['oci-modulated-stickiness'],['oci-modulated-stickiness'],['stickiness_base'],partial,Hybrid MB/MF model with separate learning rates for Stage 1 and Stage 2,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",369.7799113976207,327.05750535647087,0.35
28,"[np.float64(1.0), np.float64(1.60932848794135), np.float64(0.136871096026367), np.float64(0.0), np.float64(0.6487339481170957), np.float64(0.2354462856276305), np.float64(1.0)]","['learning_rate' 'beta' 'w' 'p_gen' 'p_rew_base' 'p_rew_oci_mod'
 'lambda_val']",7,False,"['learning_rate', 'beta', 'w', 'perseveration', 'lambd']","['p_rew_base', 'p_rew_oci_mod']","['model-based-learning', 'model-free-learning', 'eligibility-traces', 'choice-perseveration']",['reward-dependent-stickiness'],['oci-modulated-stickiness'],['p_rew_oci_mod'],partial,Two-step model with Reinforced Stickiness modulated by OCI,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",418.2194663249507,415.6525668511601,0.4833333333333333
29,"[np.float64(0.9723690134661142), np.float64(4.202037015310137), np.float64(0.3508364481082296), np.float64(0.2535886823343), np.float64(0.4303777445454181), np.float64(-2.373622227544065)]",['learning_rate' 'beta' 'w' 'stickiness' 'loss_base' 'loss_oci'],6,False,"['learning_rate', 'beta', 'w', 'perseveration']","['loss_base', 'loss_oci']","['model-free-learning', 'model-based-learning', 'choice-perseveration']",['subjective-loss-valuation'],['oci-modulated-loss'],"['loss_base', 'loss_oci']",partial,OCI-Modulated Loss Sensitivity Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",404.9113655797641,387.2739135936406,0.4833333333333333
30,"[np.float64(0.7444376237331537), np.float64(1.1096265769871394), np.float64(0.0283442579282996), np.float64(1.1922776168420288)]",['learning_rate' 'beta' 'w' 'wsls_scale'],4,False,"['learning_rate', 'beta', 'w']",['wsls_scale'],"['model-based-learning', 'model-free-learning']",['win-stay-lose-shift'],['win-stay-lose-shift'],['wsls_scale'],partial,Hybrid MB/MF Model with OCI-Modulated Win-Stay Lose-Shift (WSLS),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",549.5326707817405,452.1222177425629,0.9333333333333332
31,"[np.float64(0.1952976620497187), np.float64(1.8226196782500617), np.float64(0.0), np.float64(0.0246726909449485), np.float64(0.3285293353173733)]",['learning_rate' 'beta' 'w' 'stick_base' 'stick_oci'],5,False,"['learning_rate', 'beta', 'w']","['stick_base', 'stick_oci']","['model-based-learning', 'model-free-learning', 'hybrid-value-arbitration', 'choice-perseveration']",['OCI-modulated-stickiness'],['OCI-modulated-stickiness'],"['stick_base', 'stick_oci']",partial,OCI-Modulated Stickiness Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",579.9471739252648,515.671585604312,0.7333333333333333
32,"[np.float64(0.8452382092206586), np.float64(3.558832211444697), np.float64(0.8150693995219622), np.float64(0.5046038656153893)]",['learning_rate' 'beta' 'w' 'win_stick_oci'],4,False,"['learning_rate', 'beta', 'w']",['win_stick_oci'],"['model-based-learning', 'model-free-learning']",['win-stay-stickiness'],['oci-modulated-stickiness'],['win_stick_oci'],partial,OCI-Modulated Win-Stay Stickiness Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",400.24736890606937,396.78846508170193,0.8333333333333334
33,"[np.float64(0.3353224774102967), np.float64(3.1735395862713265), np.float64(0.112200595151824), np.float64(1.0), np.float64(0.0795552932140279), np.float64(0.5959518226993573)]",['lr' 'beta' 'w' 'lambd' 'decay_base' 'decay_oci'],6,False,"['learning_rate', 'beta', 'w', 'lambd']","['decay_base', 'decay_oci']","['model-based-learning', 'model-free-learning', 'eligibility-traces', 'mb-mf-mixing']",['unchosen-value-decay'],['oci-modulated-decay'],['decay_oci'],partial,OCI-Modulated Forgetting (Decay) Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",495.5818873885879,468.24575447610005,0.7166666666666667
34,"[np.float64(0.0249089391764472), np.float64(10.0), np.float64(1.0), np.float64(0.450439142550207), np.float64(0.4354800503682812), np.float64(0.2658503275301393)]",['learning_rate' 'beta' 'w' 'lambda_elig' 'ritual_decay' 'oci_ritual_amp'],6,False,"['learning_rate', 'beta', 'w', 'lambda_elig']","['ritual_decay', 'oci_ritual_amp']","['model-based-learning', 'model-free-learning', 'eligibility-traces']",['accumulating-ritual-bias'],['oci-modulated-ritual-bias'],['oci_ritual_amp'],partial,OCI-Modulated Ritual Bias (Accumulating Win-Stay),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",261.75895325333863,241.2091510490385,0.9
35,"[np.float64(0.7799399783756352), np.float64(2.4558472659898336), np.float64(2.940567968033396), np.float64(-6.637782664939675), np.float64(0.0), np.float64(0.1236533629802982)]","['learning_rate' 'beta_win' 'beta_loss_base' 'beta_loss_oci' 'w'
 'stickiness']",6,False,"['learning_rate', 'w']","['beta_win', 'beta_loss_base', 'beta_loss_oci', 'stickiness']","['model-based-learning', 'model-free-learning', 'perseveration-bias']",['outcome-dependent-temperature'],['OCI-modulated-exploration'],['beta_loss_oci'],partial,OCI-Modulated Exploration After Non-Reward (Post-Loss Beta),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",491.3304954895365,490.3122451702428,0.75
36,"[np.float64(0.6648949990746723), np.float64(2.073966706855182), np.float64(0.0229515210314391), np.float64(0.7088718523158628), np.float64(0.9931792359343165)]",['learning_rate' 'beta' 'w' 'p_base' 'p_oci_scale'],5,False,"['learning_rate', 'beta', 'w']","['p_base', 'p_oci_scale']","['model-based-learning', 'model-free-learning', 'choice-perseveration', 'eligibility-traces']",['oci-modulated-perseveration'],['oci-modulated-perseveration'],"['p_base', 'p_oci_scale']",partial,Hybrid RL model with OCI-modulated Perseveration (Stickiness),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",386.4734622975251,390.5992224289971,0.7833333333333333
37,"[np.float64(0.7351894209285159), np.float64(9.112510010903703), np.float64(3.5461568390166494), np.float64(0.8586952939044559), np.float64(1.0), np.float64(0.0)]",['learning_rate' 'beta_1' 'beta_2' 'lam' 'forget_base' 'stickiness'],6,False,"['learning_rate', 'beta', 'beta_2', 'lambd', 'perseveration']",['forget_base'],"['model-free-learning', 'eligibility-traces', 'choice-perseveration']",['unchosen-option-forgetting'],['unchosen-option-forgetting'],['forget_base'],partial,Pure Model-Free model with OCI-modulated Forgetting of Unchosen Options,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",322.92733134044107,265.51620141401116,0.7333333333333333
38,"[np.float64(0.8557671719992137), np.float64(1.3050383368256535), np.float64(0.9948038743108256), np.float64(0.0), np.float64(5.0), np.float64(0.1978677462451736)]",['learning_rate' 'beta' 'w' 'lambda_decay' 'stick_win' 'stick_loss_oci'],6,False,"['learning_rate', 'beta', 'w']","['lambda_decay', 'stick_win', 'stick_loss_oci']","['model-free-learning', 'model-based-learning', 'eligibility-traces']","['outcome-dependent-stickiness', 'win-stay-strategy']",['compulsive-lose-stay'],['stick_loss_oci'],partial,"Outcome-Dependent Stickiness Model (Win-Stay, Lose-Stay OCI)","['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",419.61136829159153,402.0142114270872,0.7833333333333333
39,"[np.float64(0.7696167484240588), np.float64(0.8766854310267452), np.float64(1.0407841729812823), np.float64(5.774762725083231), np.float64(8.40722298913626), np.float64(-9.214489880049207)]","['learning_rate' 'stickiness' 'beta_stage2' 'beta_mf' 'beta_mb_base'
 'beta_mb_oci']",6,False,['learning_rate'],"['stickiness', 'beta_stage2', 'beta_mf', 'beta_mb_base', 'beta_mb_oci']","['model-free-learning', 'model-based-planning', 'choice-perseveration', 'eligibility-traces']",['independent-mb-strength'],['oci-modulated-mb-strength'],['beta_mb_oci'],partial,OCI-Modulated Model-Based Beta (Independent MB/MF Strengths),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",397.4487043827186,392.94175112684013,0.7166666666666667
40,"[np.float64(0.0288899942536892), np.float64(0.7584102847433032), np.float64(1.1333145318991469), np.float64(0.528272669484418), np.float64(2.198226556624636), np.float64(1.0), np.float64(1.0)]","['lr' 'beta_base' 'beta_stiff_oci' 'w' 'stickiness' 'trace_decay'
 'lambda_eligibility']",7,False,"['learning_rate', 'beta', 'w', 'perseveration', 'lambd']","['beta_stiff_oci', 'trace_decay']","['hybrid-learning', 'eligibility-traces', 'choice-perseveration']","['habit-trace-accumulation', 'dynamic-inverse-temperature']",['oci-modulated-rigidity'],['beta_stiff_oci'],partial,Habitual Rigidity Model (Dynamic Beta),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",370.2672505628743,364.39496507338987,0.7666666666666667
41,"[np.float64(0.9230437013398612), np.float64(2.358595150785826), np.float64(0.8045954797020447), np.float64(0.2718227650104229)]",['learning_rate' 'beta' 'w_habit_low_oci' 'w_habit_high_oci'],4,False,"['learning_rate', 'beta']","['w_habit_low_oci', 'w_habit_high_oci']","['model-free-learning', 'eligibility-traces']",['mixture-policy-perseveration'],['habitual-perseveration'],"['w_habit_low_oci', 'w_habit_high_oci']",partial,Mixture of Model-Free RL and OCI-Modulated Habitual Perseveration,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",409.3410998263276,395.0470139005526,1.0
42,"[np.float64(0.703278164179492), np.float64(2.1666021579048595), np.float64(10.0), np.float64(0.0), np.float64(0.0)]",['learning_rate' 'beta_base' 'beta_win_oci' 'w' 'stickiness'],5,False,"['learning_rate', 'w']","['beta_base', 'beta_win_oci', 'stickiness']","['hybrid-learning', 'choice-perseveration', 'eligibility-traces']",['post-win-rigidity'],['post-win-rigidity'],['beta_win_oci'],partial,OCI-Modulated Post-Win Beta Rigidity Model,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",389.6452395409176,380.26143165308486,0.9666666666666668
43,"[np.float64(0.3159490227845474), np.float64(1.166600626072267), np.float64(0.0), np.float64(2.1621369808649558)]",['learning_rate' 'beta' 'w' 'persev_strength'],4,False,"['learning_rate', 'beta', 'w']",['persev_strength'],"['model-based-learning', 'model-free-learning']",['oci-modulated-perseveration'],['oci-modulated-perseveration'],['persev_strength'],partial,Hybrid Learner with OCI-Modulated Perseveration,"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",441.0912385821735,434.1778535479404,0.8666666666666667
44,"[np.float64(0.1838846498469789), np.float64(2.17472123278536), np.float64(0.3586546292599997), np.float64(1.0), np.float64(0.0097337221118252), np.float64(1.0)]",['learning_rate' 'beta' 'w' 'lambd' 'stick_weight' 'decay_base'],6,False,"['learning_rate', 'beta', 'w', 'lambd']","['stick_weight', 'decay_base']","['hybrid-learning', 'eligibility-traces']",['decaying-choice-trace'],['oci-modulated-decay'],['decay_base'],partial,Compulsive Perseveration Model (OCI-Modulated Trace Decay),"['learning_rate', 'learning_rate_2', 'beta', 'beta_2', 'w', 'lambd', 'perseveration']",524.198844100239,516.4807009987358,0.7
