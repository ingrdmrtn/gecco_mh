class ParticipantModel1(CognitiveModelBase):
    """
    HYPOTHESIS: Anxious Perseveration Model.
    High anxiety leads to increased perseveration in Stage 1 choices. Participants
    are more likely to repeat their previous Stage 1 action, with this tendency
    being amplified by their anxiety level, regardless of the previous trial's
    outcome. This represents a reduced cognitive flexibility or an increased
    reliance on habitual responses under stress.

    Parameter Bounds:
    -----------------
    alpha: [0, 1] (Learning rate for Q-values)
    beta: [0, 10] (Softmax inverse temperature)
    perseveration_bonus_base: [0, 1] (Base bonus added to the Q-value of the last chosen Stage 1 action)
    stai_perseveration_factor: [0, 1] (Factor by which STAI amplifies the perseveration bonus)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.perseveration_bonus_base, self.stai_perseveration_factor = model_parameters

    def init_model(self) -> None:
        super().init_model()
        # Initialize last_action1 to an invalid value to indicate no previous choice
        self.last_action1 = -1 

    def policy_stage1(self) -> np.ndarray:
        """
        Compute stage-1 action probabilities, applying an anxiety-amplified
        perseveration bonus to the last chosen action's Q-value, irrespective of outcome.
        """
        q_stage1_biased = np.copy(self.q_stage1)

        if self.last_action1 != -1: # Apply bias only if there was a previous trial
            # Calculate the anxiety-amplified perseveration bonus
            perseveration_bonus = self.perseveration_bonus_base + (self.stai * self.stai_perseveration_factor)
            q_stage1_biased[self.last_action1] += perseveration_bonus
        
        return self.softmax(q_stage1_biased, self.beta)
    
    # The value_update and post_trial methods from the base class are sufficient.
    # value_update performs standard TD learning.
    # post_trial correctly stores self.last_action1 for the next trial.

cognitive_model1 = make_cognitive_model(ParticipantModel1)