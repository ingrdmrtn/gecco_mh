class ParticipantModel3(CognitiveModelBase):
    """
    HYPOTHESIS: This model incorporates a common bias in decision-making: perseveration,
    which is the tendency to repeat the previous first-stage action.
    Additionally, the participant's anxiety level (medium STAI for this participant)
    is hypothesized to modulate their learning rate (`alpha`). Specifically, higher
    anxiety is proposed to lead to a slower effective learning rate, making the
    participant less reactive to recent outcomes.

    Parameter Bounds:
    -----------------
    alpha_base: [0, 1] - Base learning rate
    beta: [0, 10] - Inverse temperature for softmax
    pers_bias: [0, 5] - Perseveration bonus for repeating the last chosen first-stage action
    alpha_stai_mod: [0, 1] - Modulation factor for STAI on alpha
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha_base, self.beta, self.pers_bias, self.alpha_stai_mod = model_parameters

    def init_model(self) -> None:
        """Initialize model state, modulating alpha by STAI score."""
        # Higher STAI (anxiety) leads to lower alpha (slower learning)
        self.alpha = self.alpha_base * np.exp(-self.alpha_stai_mod * self.stai)
        # Ensure alpha is within [0, 1] and not too small
        self.alpha = np.clip(self.alpha, 0.01, 1)

    def policy_stage1(self) -> np.ndarray:
        """
        Compute stage-1 action probabilities, adding a perseveration bonus
        to the value of the last chosen first-stage action.
        """
        q_biased = self.q_stage1.copy()
        if self.last_action1 is not None:
            # Add perseveration bonus to the previously chosen first-stage action
            q_biased[self.last_action1] += self.pers_bias
        
        return self.softmax(q_biased, self.beta)

cognitive_model3 = make_cognitive_model(ParticipantModel3)