class ParticipantModel3(CognitiveModelBase):
    """
    HYPOTHESIS: High anxiety fosters behavioral rigidity by creating a perseveration bias,
    making the agent more likely to repeat its previous first-stage choice. This "stickiness"
    is a simple heuristic that reduces cognitive load. The `stai` score directly scales the 
    strength of this bias.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]     (Learning rate)
    beta: [0, 10]    (Softmax inverse temperature)
    kappa: [0, 5]     (Perseveration strength parameter)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.kappa = model_parameters

    def policy_stage1(self) -> np.ndarray:
        """
        Computes stage-1 choice probabilities by adding an anxiety-scaled
        perseveration bonus to the previously chosen action.
        """
        q_vals = self.q_stage1.copy()
        
        # Only apply bonus after the first trial
        if self.last_action1 is not None:
            # The perseveration bonus is scaled by the participant's anxiety
            perseveration_bonus = self.kappa * self.stai
            q_vals[self.last_action1] += perseveration_bonus
            
        return self.softmax(q_vals, self.beta)
    
    # The value_update method from the base class is sufficient for this model,
    # as the modification is only to the policy.

cognitive_model3 = make_cognitive_model(ParticipantModel3)