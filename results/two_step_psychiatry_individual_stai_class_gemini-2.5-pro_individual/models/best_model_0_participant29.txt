class ParticipantModel1(CognitiveModelBase):
    """
    HYPOTHESIS: High anxiety (stai) increases choice perseveration. The participant
    relies on a standard, model-free learning strategy but has a strong, anxiety-driven
    tendency to repeat the last action. This captures cognitive inflexibility often
    associated with anxiety.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]      (Learning rate)
    beta: [0, 10]     (Inverse temperature for softmax)
    perservation_base: [0, 5] (Base strength of the perseveration bonus)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.perservation_base = model_parameters

    def policy_stage1(self) -> np.ndarray:
        """
        Computes stage-1 action probabilities, adding an anxiety-modulated
        perseveration bonus to the value of the most recent choice.
        """
        # Calculate the perseveration bonus, scaled by anxiety
        perseveration_bonus = self.perservation_base * self.stai
        
        # Start with the learned Q-values
        policy_q_values = self.q_stage1.copy()
        
        # If not the first trial, add the bonus to the last chosen action
        if self.last_action1 is not None:
            policy_q_values[self.last_action1] += perseveration_bonus
            
        return self.softmax(policy_q_values, self.beta)

cognitive_model1 = make_cognitive_model(ParticipantModel1)