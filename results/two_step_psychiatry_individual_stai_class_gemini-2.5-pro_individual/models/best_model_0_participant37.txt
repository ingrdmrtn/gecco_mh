class ParticipantModel1(CognitiveModelBase):
    """
    HYPOTHESIS: This model proposes that the participant uses a hybrid of 
    model-based and model-free reinforcement learning. High anxiety (stai)
    is hypothesized to impair goal-directed, model-based planning, leading to
    a greater reliance on simpler, habitual model-free control. The weight `w` 
    is scaled by (1 - stai), so higher anxiety reduces model-based contribution.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]  (Learning rate)
    beta:  [0, 10] (Softmax inverse temperature)
    w:     [0, 1]  (Base weight for model-based control)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.w = model_parameters

    def init_model(self) -> None:
        """Initialize model-based Q-values and combined Q-values."""
        self.q_mb_stage1 = np.zeros(self.n_choices)
        self.q_combined = np.zeros(self.n_choices)

    def pre_trial(self) -> None:
        """
        Before each trial, compute model-based values and combine them
        with model-free values, modulated by anxiety.
        """
        # 1. Calculate model-based Q-values for stage 1
        # Q_MB(a) = sum_s T(s|a) * max_a' Q(s, a')
        for a1 in range(self.n_choices):
            expected_future_value = 0
            for s in range(self.n_states):
                max_q_s2 = np.max(self.q_stage2[s])
                expected_future_value += self.T[a1, s] * max_q_s2
            self.q_mb_stage1[a1] = expected_future_value
            
        # 2. Calculate the anxiety-modulated weight for model-based control
        # Higher anxiety reduces the weight of the model-based system.
        effective_w = self.w * (1 - self.stai)

        # 3. Combine model-based and model-free values
        self.q_combined = effective_w * self.q_mb_stage1 + (1 - effective_w) * self.q_stage1

    def policy_stage1(self) -> np.ndarray:
        """Compute stage-1 action probabilities using the combined Q-values."""
        return self.softmax(self.q_combined, self.beta)

cognitive_model1 = make_cognitive_model(ParticipantModel1)