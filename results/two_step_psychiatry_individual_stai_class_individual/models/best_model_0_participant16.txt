class ParticipantModel1(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Driven Perseveration]
    This model hypothesizes that high anxiety increases choice perseveration (stickiness).
    The participant is modeled as a Model-Free learner (TD learning), but their 
    probability of repeating the last Stage 1 action is boosted by a stickiness 
    parameter that is scaled by their STAI score.
    
    Mechanism:
    Q_net(a) = Q_MF(a) + (stai * stickiness_factor * IsLastAction(a))

    Parameter Bounds:
    -----------------
    alpha: [0, 1] - Learning rate
    beta: [0, 10] - Inverse temperature
    stick_factor: [0, 5] - Scaling factor for anxiety-driven stickiness
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.stick_factor = model_parameters

    def policy_stage1(self) -> np.ndarray:
        # Base Model-Free values
        q_values = self.q_stage1.copy()
        
        # Add stickiness bonus if a previous action exists
        if self.last_action1 is not None:
            # The bonus is proportional to the anxiety score (stai)
            # High anxiety -> High tendency to repeat
            bonus = self.stai * self.stick_factor
            q_values[int(self.last_action1)] += bonus
            
        return self.softmax(q_values, self.beta)

cognitive_model1 = make_cognitive_model(ParticipantModel1)