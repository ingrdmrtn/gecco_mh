class ParticipantModel2(CognitiveModelBase):
    """
    Hypothesis: Anxiety introduces an asymmetry in learning rates for positive (reward=1) 
    vs negative (reward=0) outcomes. The STAI score determines the magnitude of this bias.
    
    alpha_pos = alpha_base
    alpha_neg = alpha_base * (1 + stai * bias_factor)
    
    If bias_factor is positive, anxiety increases learning from failure.
    
    Parameter Bounds:
    -----------------
    alpha_base: [0, 1]   # Base learning rate
    beta: [0, 10]        # Inverse temperature
    bias_factor: [-1, 2] # How much STAI scales the negative learning rate
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha_base, self.beta, self.bias_factor = model_parameters

    def init_model(self) -> None:
        # Calculate specific learning rates
        self.alpha_pos = self.alpha_base
        
        # Modulate negative learning rate by STAI
        # We clip to ensure it stays within reasonable bounds [0, 1]
        raw_neg = self.alpha_base * (1.0 + self.stai * self.bias_factor)
        self.alpha_neg = np.clip(raw_neg, 0.0, 1.0)

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Determine which alpha to use based on reward
        # Assuming reward is binary 0 or 1
        if reward > 0.5:
            alpha = self.alpha_pos
        else:
            alpha = self.alpha_neg
            
        # Update Stage 2
        delta_2 = reward - self.q_stage2[state, action_2]
        self.q_stage2[state, action_2] += alpha * delta_2
        
        # Update Stage 1
        # Using the updated stage 2 value as the target for stage 1
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        self.q_stage1[action_1] += alpha * delta_1

cognitive_model2 = make_cognitive_model(ParticipantModel2)