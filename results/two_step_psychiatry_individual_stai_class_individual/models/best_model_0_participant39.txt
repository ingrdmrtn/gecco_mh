class ParticipantModel2(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety drives "Safety Behavior" via Perseveration.
    Anxious individuals often exhibit rigidity or a tendency to stick with 
    familiar choices to minimize cognitive load or perceived risk.
    This model adds a "perseverance bonus" to the Q-value of the previously 
    chosen Stage 1 action. The magnitude of this stickiness is modulated by STAI.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]        # Learning rate
    beta: [0, 10]        # Inverse temperature
    persev_w: [0, 5]     # Weight of perseverance bonus, scaled by STAI
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.persev_w = model_parameters

    def policy_stage1(self) -> np.ndarray:
        # Create a temporary copy of Q-values for decision making
        # so we don't corrupt the actual learned values
        q_decision = self.q_stage1.copy()
        
        # If this isn't the first trial, apply the perseverance bonus
        if self.last_action1 is not None:
            # The bonus is the base weight scaled by the anxiety score
            bonus = self.persev_w * self.stai
            q_decision[int(self.last_action1)] += bonus
            
        return self.softmax(q_decision, self.beta)

cognitive_model2 = make_cognitive_model(ParticipantModel2)