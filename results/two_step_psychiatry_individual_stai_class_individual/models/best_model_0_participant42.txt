class ParticipantModel2(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Modulated Memory Decay]
    This model hypothesizes that anxiety consumes cognitive resources (working memory),
    leading to faster decay (forgetting) of learned values for options that are not
    currently being chosen. High anxiety accelerates this decay, causing the participant
    to revert to neutral values (0) for unvisited states/actions more quickly.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]          - Learning rate
    beta: [0, 10]          - Inverse temperature
    decay_base: [0, 1]     - Baseline decay rate
    decay_stai: [0, 1]     - Additional decay per unit of STAI
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.decay_base, self.decay_stai = model_parameters
        
        # Calculate total decay rate, clipped to [0, 1]
        raw_decay = self.decay_base + (self.decay_stai * self.stai)
        self.decay_rate = np.clip(raw_decay, 0.0, 1.0)

    def post_trial(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        super().post_trial(action_1, state, action_2, reward)
        
        # Decay unchosen Stage 1 option
        unchosen_1 = 1 - action_1
        self.q_stage1[unchosen_1] *= (1.0 - self.decay_rate)
        
        # Decay unchosen Stage 2 option in the visited state
        unchosen_2 = 1 - action_2
        self.q_stage2[state, unchosen_2] *= (1.0 - self.decay_rate)
        
        # Note: We could also decay the unvisited state's values, but standard
        # forgetting models often focus on the active context or global decay.
        # Here we decay the unvisited state as well to represent global memory loss.
        unvisited_state = 1 - state
        self.q_stage2[unvisited_state, :] *= (1.0 - self.decay_rate)

cognitive_model2 = make_cognitive_model(ParticipantModel2)