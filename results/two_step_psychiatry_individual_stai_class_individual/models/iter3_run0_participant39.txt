```python
class ParticipantModel1(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety-Driven Catastrophizing (Reward Bias).
    Anxious individuals may perceive neutral outcomes (0 coins) or losses as 
    significantly worse than they objectively are. This model introduces a 
    "worry penalty" that subtracts value from the reward signal when the 
    outcome is non-positive, scaled by the participant's STAI score. This
    leads to faster avoidance of options that yield 0 or negative rewards.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]        # Learning rate
    beta: [0, 10]        # Inverse temperature
    worry_k: [0, 5]      # Magnitude of negative bias, scaled by STAI
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.worry_k = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Apply catastrophizing bias: if reward is not positive, it feels worse
        effective_reward = reward
        if reward <= 0:
            effective_reward -= (self.worry_k * self.stai)
            
        # Standard TD update with effective_reward
        delta_2 = effective_reward - self.q_stage2[state, action_2]
        self.q_stage2[state, action_2] += self.alpha * delta_2
        
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        self.q_stage1[action_1] += self.alpha * delta_1

cognitive_model1 = make_cognitive_model(ParticipantModel1)


class ParticipantModel2(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety-Induced Memory Decay.
    High anxiety consumes cognitive resources (working memory capacity), leading 
    to faster forgetting of learned values. This model implements a passive 
    decay of Q-values towards zero on every trial, with the decay rate 
    proportional to the STAI score. This makes the participant rely more heavily
    on very recent outcomes.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]        # Learning rate
    beta: [0, 10]        # Inverse temperature
    decay_k: [0, 1]      # Decay scaling factor (decay_rate = decay_k * STAI)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.decay_k = model_parameters

    def pre_trial(self) -> None:
        # Calculate decay factor based on anxiety
        # We clamp the decay to ensure it doesn't invert values or go > 1
        decay_rate = self.decay_k * self.stai
        decay_rate = np.clip(decay_rate, 0.0, 1.0)
        
        # Apply decay to all Q-values (forgetting)
        self.q_stage1 *= (1.0 - decay_rate)
        self.q_stage2 *= (1.0 - decay_rate)

cognitive_model2 = make_cognitive_model(ParticipantModel2)


class ParticipantModel3(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety-Driven Transition Mistrust.
    When anxious individuals experience a "rare" transition (e.g., Spaceship A 
    going to Planet Y), they may overreact and lose confidence in their choice, 
    viewing the spaceship as unreliable. This model applies a specific penalty 
    to the Stage 1 Q-value immediately after a rare transition occurs, 
    discouraging the reuse of that spaceship regardless of the reward obtained.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]        # Learning rate
    beta: [0, 10]        # Inverse temperature
    mistrust_k: [0, 5]   # Penalty magnitude for rare transitions, scaled by STAI
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.mistrust_k = model_parameters

    def post_trial(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        super().post_trial(action_1, state, action_2, reward)
        
        # Determine if the transition was rare
        # Common: A(0)->X(0) or U(1)->Y(1). Rare: A(0)->Y(1) or U(1)->X(0).
        # This is equivalent to checking if action_1 != state
        is_rare_transition = (action_1 != state)
        
        if is_rare_transition:
            # Apply mistrust penalty scaled by anxiety
            penalty = self.mistrust_k * self.stai
            self.q_stage1[action_1] -= penalty

cognitive_model3 = make_cognitive_model(ParticipantModel3)
```