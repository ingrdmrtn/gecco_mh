Here are three new cognitive models that hypothesize different mechanisms for how anxiety (STAI) influences decision-making in this task.

### Model 1: Anxiety-Driven Choice Perseveration
This model hypothesizes that high anxiety leads to a "safety behavior" strategy manifesting as repetition (stickiness). Anxious participants are more likely to repeat their previous choice to avoid the cognitive load or perceived risk of switching, regardless of the outcome.

```python
class ParticipantModel1(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Driven Choice Perseveration]
    High anxiety leads to rigid, repetitive behavior (stickiness) to reduce uncertainty.
    This is modeled as a bonus added to the value of the previously chosen action,
    proportional to the participant's STAI score.
    
    Logits(a) = Q(a) + (k_stick * STAI * I(a == last_action))

    Parameter Bounds:
    -----------------
    alpha: [0, 1]      - Learning rate
    beta: [0, 10]      - Inverse temperature
    k_stick: [0, 5]    - Stickiness magnitude scaled by anxiety
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.k_stick = model_parameters

    def policy_stage1(self) -> np.ndarray:
        # Copy values to avoid modifying the actual Q-values permanently for this step
        logits = self.q_stage1.copy()
        
        # Add stickiness bonus if there was a previous action
        if self.last_action1 is not None:
            # The bonus is scaled by the anxiety score (STAI)
            bonus = self.k_stick * self.stai
            logits[int(self.last_action1)] += bonus
            
        return self.softmax(logits, self.beta)

cognitive_model1 = make_cognitive_model(ParticipantModel1)
```

### Model 2: Anxiety-Modulated Negative Learning Suppression
This model hypothesizes that anxious individuals may exhibit a specific bias in how they process failure. Rather than learning from 0-coin outcomes (negative prediction errors), they may suppress this information (denial or avoidance), leading to a lower effective learning rate for negative outcomes compared to positive ones.

```python
class ParticipantModel2(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Modulated Negative Learning Suppression]
    Anxious individuals may under-weight negative outcomes (0 coins) to maintain 
    a sense of safety or competence. This is modeled by reducing the learning rate 
    specifically when the prediction error is negative, scaled by STAI.
    
    If delta < 0: alpha_eff = alpha * (1 - nu_suppress * STAI)

    Parameter Bounds:
    -----------------
    alpha: [0, 1]        - Base learning rate (for positive outcomes)
    beta: [0, 10]        - Inverse temperature
    nu_suppress: [0, 1]  - Degree to which anxiety suppresses negative learning
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.nu_suppress = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Stage 2 Update
        delta_2 = reward - self.q_stage2[state, action_2]
        
        # Determine effective alpha for Stage 2
        alpha_2 = self.alpha
        if delta_2 < 0:
            # Suppress learning from negative prediction errors based on anxiety
            alpha_2 *= (1.0 - (self.nu_suppress * self.stai))
            # Ensure alpha doesn't go below 0
            alpha_2 = max(0.0, alpha_2)
            
        self.q_stage2[state, action_2] += alpha_2 * delta_2
        
        # Stage 1 Update
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        
        # Determine effective alpha for Stage 1
        alpha_1 = self.alpha
        if delta_1 < 0:
            alpha_1 *= (1.0 - (self.nu_suppress * self.stai))
            alpha_1 = max(0.0, alpha_1)

        self.q_stage1[action_1] += alpha_1 * delta_1

cognitive_model2 = make_cognitive_model(ParticipantModel2)
```

### Model 3: Anxiety-Induced Rigidity (Arousal)
This model hypothesizes that anxiety acts as a physiological arousal factor that narrows attention and makes choices more deterministic. Instead of a specific bias, anxiety increases the "gain" of the decision function (inverse temperature), making the participant more likely to exploit small differences in value and less likely to explore.

```python
class ParticipantModel3(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Induced Rigidity / Arousal]
    Anxiety increases physiological arousal, leading to more deterministic (rigid) 
    decision-making. This is modeled by scaling the softmax inverse temperature (beta) 
    by the STAI score. Higher anxiety results in a higher beta (less randomness).
    
    beta_effective = beta_base + (arousal_gain * STAI)

    Parameter Bounds:
    -----------------
    alpha: [0, 1]         - Learning rate
    beta_base: [0, 10]    - Baseline inverse temperature (for low anxiety)
    arousal_gain: [0, 10] - How much anxiety increases rigidity/beta
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta_base, self.arousal_gain = model_parameters

    def policy_stage1(self) -> np.ndarray:
        # Calculate effective beta based on anxiety
        beta_eff = self.beta_base + (self.arousal_gain * self.stai)
        return self.softmax(self.q_stage1, beta_eff)

    def policy_stage2(self, state: int) -> np.ndarray:
        # Calculate effective beta based on anxiety
        beta_eff = self.beta_base + (self.arousal_gain * self.stai)
        return self.softmax(self.q_stage2[state], beta_eff)

cognitive_model3 = make_cognitive_model(ParticipantModel3)
```