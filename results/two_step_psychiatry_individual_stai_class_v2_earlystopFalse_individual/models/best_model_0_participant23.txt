class ParticipantModel1(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Modulated Negativity Bias]
    This model hypothesizes that anxiety specifically modulates learning from negative prediction errors 
    (disappointments), while learning from positive prediction errors remains constant.
    Anxious individuals may be hypersensitive (or hyposensitive) to outcomes that are worse than expected,
    updating their beliefs more drastically when things go wrong.

    Parameter Bounds:
    -----------------
    alpha_pos: [0, 1] (Learning rate for positive RPEs)
    beta: [0, 10]
    alpha_neg_base: [0, 1] (Base learning rate for negative RPEs)
    alpha_neg_anx: [-1, 1] (Modulation of negative learning rate by anxiety)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha_pos, self.beta, self.alpha_neg_base, self.alpha_neg_anx = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Calculate alpha_neg based on STAI
        alpha_neg = self.alpha_neg_base + (self.alpha_neg_anx * self.stai)
        alpha_neg = np.clip(alpha_neg, 0.0, 1.0)

        # Stage 2 Update
        delta_2 = reward - self.q_stage2[state, action_2]
        # Use alpha_pos if outcome was better than expected, alpha_neg if worse
        alpha_2 = self.alpha_pos if delta_2 >= 0 else alpha_neg
        self.q_stage2[state, action_2] += alpha_2 * delta_2
        
        # Stage 1 Update
        # We apply the same asymmetry logic to the Stage 1 prediction error
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        alpha_1 = self.alpha_pos if delta_1 >= 0 else alpha_neg
        self.q_stage1[action_1] += alpha_1 * delta_1

cognitive_model1 = make_cognitive_model(ParticipantModel1)