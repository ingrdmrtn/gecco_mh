class ParticipantModel1(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety modulates the asymmetry between learning from positive and negative prediction errors.
    The participant has a base learning rate for positive outcomes, but their learning rate for 
    negative outcomes (getting 0 coins) is scaled by their anxiety level. 
    
    If the scaling factor is low, high anxiety might suppress learning from failures (ignoring 0s), 
    leading to persistence. If high, it might cause over-reaction.
    
    Parameter Bounds:
    -----------------
    alpha_pos: [0, 1]      # Learning rate for positive prediction errors
    neg_scale_base: [0, 5] # Base scaling factor for negative learning rate
    beta: [0, 10]          # Inverse temperature
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha_pos, self.neg_scale_base, self.beta = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Calculate Stage 2 Prediction Error
        delta_2 = reward - self.q_stage2[state, action_2]
        
        # Determine learning rate based on sign of PE and anxiety
        # We model the negative learning rate as dependent on STAI
        # alpha_neg = alpha_pos * neg_scale_base * (1 +/- STAI effect)
        # Here we try: alpha_neg is modulated by STAI directly.
        # A simple interaction: alpha_neg = alpha_pos * neg_scale_base * stai
        # This implies anxiety changes the ratio of positive/negative learning.
        
        alpha_neg = self.alpha_pos * self.neg_scale_base * self.stai
        
        # Clip alpha_neg to be reasonable [0, 1]
        alpha_neg = np.clip(alpha_neg, 0.0, 1.0)
        
        eff_alpha_2 = self.alpha_pos if delta_2 >= 0 else alpha_neg
        self.q_stage2[state, action_2] += eff_alpha_2 * delta_2
        
        # Stage 1 update
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        eff_alpha_1 = self.alpha_pos if delta_1 >= 0 else alpha_neg
        self.q_stage1[action_1] += eff_alpha_1 * delta_1

cognitive_model1 = make_cognitive_model(ParticipantModel1)