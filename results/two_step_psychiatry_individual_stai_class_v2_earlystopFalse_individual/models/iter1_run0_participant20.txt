```python
import numpy as np
from abc import ABC, abstractmethod

class ParticipantModel1(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety-Induced Decision Noise.
    
    This model hypothesizes that high anxiety acts as a cognitive disruptor, 
    increasing the "temperature" of the softmax decision process. 
    Higher anxiety leads to more random (noisier) choices, reducing the 
    participant's ability to consistently exploit learned values.
    
    The inverse temperature (beta) is scaled down by the STAI score.
    beta_effective = beta / (1 + noise_param * STAI)

    Parameter Bounds:
    -----------------
    alpha: [0, 1]
    beta: [0, 10]
    noise_param: [0, 10] (Scales the impact of anxiety on noise)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.noise_param = model_parameters

    def policy_stage1(self) -> np.ndarray:
        # Calculate effective beta based on anxiety
        # Higher STAI -> Lower effective beta -> More noise (flatter softmax)
        beta_eff = self.beta / (1.0 + self.noise_param * self.stai)
        return self.softmax(self.q_stage1, beta_eff)

    def policy_stage2(self, state: int) -> np.ndarray:
        # Apply same noise scaling to stage 2
        beta_eff = self.beta / (1.0 + self.noise_param * self.stai)
        return self.softmax(self.q_stage2[state], beta_eff)

cognitive_model1 = make_cognitive_model(ParticipantModel1)

class ParticipantModel2(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety-Driven Negativity Bias.
    
    This model hypothesizes that anxious individuals exhibit a "negativity bias" 
    in learning. They update their value estimates more drastically when 
    outcomes are worse than expected (negative prediction errors) compared 
    to when they are better than expected.
    
    The learning rate alpha is boosted by STAI when the prediction error is negative.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]
    beta: [0, 10]
    neg_bias: [0, 5] (Multiplier for learning rate on negative errors)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.neg_bias = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Stage 2 Update
        delta_2 = reward - self.q_stage2[state, action_2]
        
        # Determine learning rate for Stage 2
        if delta_2 < 0:
            # Boost learning rate for negative errors based on anxiety
            alpha_2 = self.alpha * (1.0 + self.neg_bias * self.stai)
            alpha_2 = min(alpha_2, 1.0) # Cap at 1.0
        else:
            alpha_2 = self.alpha
            
        self.q_stage2[state, action_2] += alpha_2 * delta_2
        
        # Stage 1 Update
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        
        # Determine learning rate for Stage 1
        if delta_1 < 0:
            alpha_1 = self.alpha * (1.0 + self.neg_bias * self.stai)
            alpha_1 = min(alpha_1, 1.0)
        else:
            alpha_1 = self.alpha
            
        self.q_stage1[action_1] += alpha_1 * delta_1

cognitive_model2 = make_cognitive_model(ParticipantModel2)

class ParticipantModel3(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety-Accelerated Forgetting.
    
    This model hypothesizes that anxiety consumes working memory resources, 
    leading to faster decay (forgetting) of value representations for 
    options that are not currently being chosen.
    
    After each trial, the Q-values of unchosen options decay towards their 
    initial values at a rate proportional to the STAI score.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]
    beta: [0, 10]
    decay_rate: [0, 1] (Base decay rate scaled by STAI)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.decay_rate = model_parameters

    def post_trial(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        super().post_trial(action_1, state, action_2, reward)
        
        # Calculate decay factor
        # decay is between 0 (no forgetting) and 1 (instant forgetting)
        decay = self.decay_rate * self.stai
        decay = np.clip(decay, 0, 1)
        
        # Decay unchosen Stage 1 option towards 0 (initialization value)
        unchosen_a1 = 1 - action_1
        self.q_stage1[unchosen_a1] *= (1.0 - decay)
        
        # Decay unchosen Stage 2 option in the visited state towards 0.5 (initialization value)
        unchosen_a2 = 1 - action_2
        target_val = 0.5
        self.q_stage2[state, unchosen_a2] = (self.q_stage2[state, unchosen_a2] * (1.0 - decay)) + (target_val * decay)

cognitive_model3 = make_cognitive_model(ParticipantModel3)
```