```python
import numpy as np

class ParticipantModel1(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety modulates the balance between Model-Based (MB) and Model-Free (MF) control.
    
    Anxiety consumes cognitive resources, potentially shifting control from the computationally 
    expensive Model-Based system (planning) to the cheaper Model-Free system (habit).
    Alternatively, anxiety might increase monitoring, boosting MB control.
    
    We model the net Q-value as a weighted mixture:
    Q_net(s1, a) = w * Q_MB(s1, a) + (1 - w) * Q_MF(s1, a)
    
    The mixing weight 'w' is modulated by STAI via a sigmoid function:
    w = 1 / (1 + exp(-k * (STAI - 0.4)))
    
    If k < 0: Higher anxiety -> Lower w (More Model-Free/Habitual)
    If k > 0: Higher anxiety -> Higher w (More Model-Based/Deliberative)
    
    Parameter Bounds:
    -----------------
    alpha: [0, 1]       # Learning rate for MF values and Stage 2 values
    beta: [0, 10]       # Inverse temperature
    k: [-10, 10]        # Slope of anxiety effect on MB/MF balance
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.k = model_parameters

    def policy_stage1(self) -> np.ndarray:
        # 1. Calculate Model-Based values
        # V(s') = max_a Q_stage2(s', a)
        max_q_stage2 = np.max(self.q_stage2, axis=1) # Shape (n_states,)
        
        # Q_MB(a) = sum_s' T(a, s') * V(s')
        # self.T is shape (n_choices, n_states)
        q_mb = self.T @ max_q_stage2
        
        # 2. Calculate Mixing Weight w based on STAI
        # Centering STAI at 0.4 (approx population mean/boundary)
        # Sigmoid to keep w in [0, 1]
        w = 1.0 / (1.0 + np.exp(-self.k * (self.stai - 0.4)))
        
        # 3. Combine MB and MF values
        # self.q_stage1 represents the Model-Free values learned via TD
        q_net = w * q_mb + (1.0 - w) * self.q_stage1
        
        return self.softmax(q_net, self.beta)

cognitive_model1 = make_cognitive_model(ParticipantModel1)


class ParticipantModel2(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety modulates sensitivity to negative prediction errors (Loss Aversion).
    
    Anxious individuals may be more sensitive to outcomes that are worse than expected 
    (negative prediction errors) compared to outcomes that are better than expected.
    
    We implement asymmetric learning rates:
    alpha_pos = alpha
    alpha_neg = alpha * (1 + lambda * STAI)
    
    If lambda > 0: Anxiety amplifies learning from negative surprises (punishment sensitivity).
    
    Parameter Bounds:
    -----------------
    alpha: [0, 1]       # Base learning rate (for positive PEs)
    beta: [0, 10]       # Inverse temperature
    lam: [-5, 5]        # Anxiety modulation of negative learning rate
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.lam = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Calculate effective negative learning rate
        # Clip to ensure stability (0 to 1)
        alpha_neg_raw = self.alpha * (1.0 + self.lam * self.stai)
        alpha_neg = np.clip(alpha_neg_raw, 0.0, 1.0)
        
        # --- Stage 2 Update ---
        delta_2 = reward - self.q_stage2[state, action_2]
        
        if delta_2 >= 0:
            self.q_stage2[state, action_2] += self.alpha * delta_2
        else:
            self.q_stage2[state, action_2] += alpha_neg * delta_2
        
        # --- Stage 1 Update ---
        # Note: Standard TD uses Q_stage2 as the target
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        
        if delta_1 >= 0:
            self.q_stage1[action_1] += self.alpha * delta_1
        else:
            self.q_stage1[action_1] += alpha_neg * delta_1

cognitive_model2 = make_cognitive_model(ParticipantModel2)


class ParticipantModel3(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety modulates the exploration-exploitation trade-off (Inverse Temperature).
    
    Anxiety might lead to more rigid, exploitative behavior (safety seeking) or 
    more erratic, random behavior (panic/confusion). This is modeled by modulating 
    the softmax beta parameter.
    
    beta_eff = beta_base + phi * STAI
    
    If phi > 0: Anxiety increases beta (more deterministic/rigid).
    If phi < 0: Anxiety decreases beta (more random/exploratory).
    
    Parameter Bounds:
    -----------------
    alpha: [0, 1]       # Learning rate
    beta_base: [0, 10]  # Baseline inverse temperature
    phi: [-10, 10]      # Anxiety modulation of beta
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta_base, self.phi = model_parameters
        
        # Calculate effective beta immediately
        beta_eff = self.beta_base + self.phi * self.stai
        
        # Ensure beta stays non-negative
        self.beta = np.maximum(beta_eff, 0.0)

    # No need to override policy methods; they use self.beta which we just set.
    # No need to override value_update; it uses self.alpha which is standard.

cognitive_model3 = make_cognitive_model(ParticipantModel3)
```