```python
class ParticipantModel1(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Modulated Model-Based Deficit]
    This model hypothesizes that anxiety consumes cognitive resources, reducing the 
    capacity for Model-Based (planning) control. The weight assigned to the Model-Based 
    system (which uses the transition structure) decreases as anxiety (STAI) increases.
    
    The decision at Stage 1 is a mixture of Model-Free (habitual) and Model-Based (planning) values.
    The mixing weight w_MB is modulated by STAI: w_MB = mb_max * (1 - stai).

    Parameter Bounds:
    -----------------
    alpha: [0, 1]
    beta: [0, 10]
    mb_max: [0, 1] (Maximum weight given to MB system when anxiety is 0)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.mb_max = model_parameters

    def policy_stage1(self) -> np.ndarray:
        # 1. Calculate Model-Based Values
        # Q_MB(a1) = Sum_s [ P(s|a1) * max_a2 Q_stage2(s, a2) ]
        # self.T is shape (2, 2) -> (action1, state)
        # self.q_stage2 is shape (2, 2) -> (state, action2)
        
        max_q2 = np.max(self.q_stage2, axis=1) # Shape (2,) - max value of each state
        q_mb = np.dot(self.T, max_q2) # Shape (2,)
        
        # 2. Retrieve Model-Free Values (maintained in self.q_stage1 by base class update)
        q_mf = self.q_stage1
        
        # 3. Calculate Mixing Weight
        # Higher anxiety -> Lower w_mb (less planning)
        w_mb = self.mb_max * (1.0 - self.stai)
        w_mb = np.clip(w_mb, 0.0, 1.0)
        
        # 4. Combine
        q_net = w_mb * q_mb + (1 - w_mb) * q_mf
        
        return self.softmax(q_net, self.beta)

cognitive_model1 = make_cognitive_model(ParticipantModel1)

class ParticipantModel2(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Amplified Negative Learning]
    This model hypothesizes that anxious individuals are hyper-sensitive to negative outcomes 
    (prediction errors < 0). They update their value estimates more drastically when 
    expectations are not met compared to when they are met or exceeded.
    
    The learning rate for negative prediction errors is scaled by anxiety.

    Parameter Bounds:
    -----------------
    alpha: [0, 1] (Base learning rate)
    beta: [0, 10]
    neg_amp: [0, 5] (Amplification factor for negative errors based on STAI)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.neg_amp = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Stage 2 Update
        delta_2 = reward - self.q_stage2[state, action_2]
        
        # Determine effective alpha for Stage 2
        if delta_2 < 0:
            alpha_eff_2 = self.alpha * (1.0 + self.neg_amp * self.stai)
            alpha_eff_2 = np.clip(alpha_eff_2, 0.0, 1.0)
        else:
            alpha_eff_2 = self.alpha
            
        self.q_stage2[state, action_2] += alpha_eff_2 * delta_2
        
        # Stage 1 Update
        # Note: In standard TD, Stage 1 updates towards Stage 2 value (Q2).
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        
        # Determine effective alpha for Stage 1
        if delta_1 < 0:
            alpha_eff_1 = self.alpha * (1.0 + self.neg_amp * self.stai)
            alpha_eff_1 = np.clip(alpha_eff_1, 0.0, 1.0)
        else:
            alpha_eff_1 = self.alpha

        self.q_stage1[action_1] += alpha_eff_1 * delta_1

cognitive_model2 = make_cognitive_model(ParticipantModel2)

class ParticipantModel3(CognitiveModelBase):
    """
    [HYPOTHESIS: Anxiety-Induced Structure Blindness]
    This model hypothesizes that anxiety promotes a "flat" or "direct" association 
    between the first-stage choice and the final reward, ignoring the intermediate 
    state structure (the planets).
    
    Standard TD learning updates Stage 1 values towards Stage 2 values.
    This model mixes that with a direct update towards the Reward.
    The weight of the direct (structure-blind) update increases with anxiety.

    Parameter Bounds:
    -----------------
    alpha: [0, 1]
    beta: [0, 10]
    flat_bias: [0, 1] (Scaling factor for how much STAI induces flat learning)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.flat_bias = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Stage 2 Update (Standard)
        delta_2 = reward - self.q_stage2[state, action_2]
        self.q_stage2[state, action_2] += self.alpha * delta_2
        
        # Stage 1 Update (Modified)
        # Target 1: Structure-sensitive (TD) -> Q_stage2
        target_structure = self.q_stage2[state, action_2]
        
        # Target 2: Structure-blind (Direct) -> Reward
        target_flat = reward
        
        # Mixing weight rho depends on anxiety
        # rho = 0 -> Pure TD (Structure sensitive)
        # rho = 1 -> Pure Direct (Structure blind)
        rho = self.flat_bias * self.stai
        rho = np.clip(rho, 0.0, 1.0)
        
        combined_target = (1 - rho) * target_structure + rho * target_flat
        
        delta_1 = combined_target - self.q_stage1[action_1]
        self.q_stage1[action_1] += self.alpha * delta_1

cognitive_model3 = make_cognitive_model(ParticipantModel3)
```