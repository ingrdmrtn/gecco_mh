Here are 3 new cognitive models exploring different mechanisms for how anxiety (STAI) might influence decision-making in this task, specifically addressing the observed perseveration and reward sensitivity.

### Model 1: Anxiety-Modulated Model-Based/Model-Free Hybrid
This model hypothesizes that anxiety shifts the balance between Model-Based (planning using transition probabilities) and Model-Free (habitual) control. Specifically, higher anxiety might impair Model-Based reasoning, leading to a reliance on Model-Free habits which are slower to update and more prone to perseveration.

```python
import numpy as np
from abc import ABC, abstractmethod

class ParticipantModel1(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety modulates the trade-off between Model-Based (MB) and Model-Free (MF) control.
    Higher anxiety (STAI) reduces the weight (w) of the Model-Based system, leading to more habitual behavior.
    The mixing weight 'w' is calculated as: w = w_base * (1 - stai).
    
    Parameter Bounds:
    -----------------
    alpha: [0, 1]       # Learning rate
    beta: [0, 10]       # Inverse temperature
    w_base: [0, 1]      # Base weight for Model-Based control (before anxiety reduction)
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta, self.w_base = model_parameters

    def init_model(self) -> None:
        # Initialize transition matrix (fixed for simplicity as per task description)
        # A -> X (0.7), A -> Y (0.3); U -> X (0.3), U -> Y (0.7)
        # Indices: 0=A, 1=U; 0=X, 1=Y
        self.T = np.array([[0.7, 0.3], [0.3, 0.7]]) 

    def policy_stage1(self) -> np.ndarray:
        # Model-Free values (Q_MF) are just self.q_stage1
        
        # Model-Based values (Q_MB)
        # Q_MB(a) = sum(P(s'|a) * max(Q_stage2(s', :)))
        q_mb = np.zeros(self.n_choices)
        for a in range(self.n_choices):
            for s_prime in range(self.n_states):
                # Max Q value at stage 2 for state s_prime
                max_q2 = np.max(self.q_stage2[s_prime])
                q_mb[a] += self.T[a, s_prime] * max_q2
        
        # Calculate mixing weight modulated by anxiety
        # Higher STAI -> Lower w -> Less Model-Based
        w = self.w_base * (1.0 - self.stai)
        w = np.clip(w, 0.0, 1.0)
        
        # Integrated Q-values
        q_net = w * q_mb + (1 - w) * self.q_stage1
        
        return self.softmax(q_net, self.beta)

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Stage 2 update (Standard Q-learning)
        delta_2 = reward - self.q_stage2[state, action_2]
        self.q_stage2[state, action_2] += self.alpha * delta_2
        
        # Stage 1 Model-Free update (TD(1) / SARSA-like logic for MF path)
        # Using the actual value of the second stage choice
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        self.q_stage1[action_1] += self.alpha * delta_1

cognitive_model1 = make_cognitive_model(ParticipantModel1)
```

### Model 2: Anxiety-Induced Learning Rate Asymmetry
This model hypothesizes that anxiety affects how participants learn from positive versus negative prediction errors. Specifically, anxious individuals might be hypersensitive to negative outcomes (punishment) or hyposensitive to positive outcomes (reward), leading to different learning rates. This model scales the learning rate for negative prediction errors based on STAI.

```python
class ParticipantModel2(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety induces an asymmetry in learning from positive vs negative prediction errors.
    The learning rate for negative prediction errors (alpha_neg) is scaled by STAI relative to the 
    positive learning rate (alpha_pos).
    alpha_neg = alpha_pos * (1 + neg_bias_param * stai)
    
    Parameter Bounds:
    -----------------
    alpha_pos: [0, 1]       # Learning rate for positive prediction errors
    beta: [0, 10]           # Inverse temperature
    neg_bias_param: [0, 5]  # Scaling factor for negative learning bias due to anxiety
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha_pos, self.beta, self.neg_bias_param = model_parameters

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Calculate effective negative learning rate
        # If neg_bias_param > 0, higher anxiety increases learning from disappointment
        alpha_neg = self.alpha_pos * (1.0 + self.neg_bias_param * self.stai)
        alpha_neg = np.clip(alpha_neg, 0.0, 1.0) # Ensure it stays valid

        # Stage 2 update
        delta_2 = reward - self.q_stage2[state, action_2]
        alpha_2 = self.alpha_pos if delta_2 >= 0 else alpha_neg
        self.q_stage2[state, action_2] += alpha_2 * delta_2
        
        # Stage 1 update
        # Note: In standard TD, we update Q1 based on Q2. 
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        alpha_1 = self.alpha_pos if delta_1 >= 0 else alpha_neg
        self.q_stage1[action_1] += alpha_1 * delta_1

cognitive_model2 = make_cognitive_model(ParticipantModel2)
```

### Model 3: Anxiety-Driven Exploration Suppression
This model hypothesizes that anxiety suppresses exploration. Instead of a fixed softmax temperature (beta), the inverse temperature is modulated by anxiety. Higher anxiety leads to a higher beta (lower temperature), making choices more deterministic and "stiff," effectively sticking to the option with the slightly higher value and ignoring potential information gain from the other option.

```python
class ParticipantModel3(CognitiveModelBase):
    """
    HYPOTHESIS: Anxiety suppresses exploration by increasing the inverse temperature (beta).
    Anxious participants are more 'exploitative' or rigid in their choices to avoid uncertainty.
    Effective beta = beta_base * (1 + stiff_scale * stai).
    
    Parameter Bounds:
    -----------------
    alpha: [0, 1]         # Learning rate
    beta_base: [0, 10]    # Base inverse temperature
    stiff_scale: [0, 10]  # How much anxiety increases rigidity/stiffness
    """

    def unpack_parameters(self, model_parameters: tuple) -> None:
        self.alpha, self.beta_base, self.stiff_scale = model_parameters

    def policy_stage1(self) -> np.ndarray:
        # Calculate anxiety-modulated beta
        # Higher STAI -> Higher Beta -> More deterministic (less exploration)
        effective_beta = self.beta_base * (1.0 + self.stiff_scale * self.stai)
        return self.softmax(self.q_stage1, effective_beta)

    def policy_stage2(self, state: int) -> np.ndarray:
        # Apply the same rigidity to stage 2
        effective_beta = self.beta_base * (1.0 + self.stiff_scale * self.stai)
        return self.softmax(self.q_stage2[state], effective_beta)

    def value_update(self, action_1: int, state: int, action_2: int, reward: float) -> None:
        # Standard TD learning
        delta_2 = reward - self.q_stage2[state, action_2]
        self.q_stage2[state, action_2] += self.alpha * delta_2
        
        delta_1 = self.q_stage2[state, action_2] - self.q_stage1[action_1]
        self.q_stage1[action_1] += self.alpha * delta_1

cognitive_model3 = make_cognitive_model(ParticipantModel3)
```