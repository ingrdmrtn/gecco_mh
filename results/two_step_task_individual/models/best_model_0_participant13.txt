def cognitive_model1(action_1, state, action_2, reward, model_parameters):
    """Hybrid model-based/model-free with eligibility trace and first-stage perseveration.
    Returns negative log-likelihood of observed first- and second-stage choices.

    Parameters
    ----------
    action_1 : array-like of int (0 or 1)
        Chosen spaceship at stage 1 on each trial (0=A, 1=U).
    state : array-like of int (0 or 1)
        Reached planet on each trial (0=X, 1=Y).
    action_2 : array-like of int (0 or 1)
        Chosen alien at stage 2 on each trial (planet-specific).
    reward : array-like of float in [0,1]
        Coins received on each trial.
    model_parameters : iterable of 5 floats
        [alpha, beta, w, lam, kappa]
        - alpha in [0,1]: learning rate for value updates (both stages).
        - beta in [0,10]: inverse temperature for both stages.
        - w in [0,1]: weight on model-based values at stage 1 (1=fully MB, 0=fully MF).
        - lam in [0,1]: eligibility trace mixing for bootstrapping with outcome.
        - kappa in [0,1]: first-stage perseveration strength; mapped to [-1,1] internally.

    Notes
    -----
    - Transition structure is fixed and known (common=0.7).
    - Stage-1 decision uses a hybrid MB/MF action value with perseveration bias.
    - Stage-2 decision uses MF action values.
    """
    alpha, beta, w, lam, kappa = model_parameters
    n_trials = len(action_1)

    transition_matrix = np.array([[0.7, 0.3],
                                  [0.3, 0.7]])
    p_choice_1 = np.zeros(n_trials)
    p_choice_2 = np.zeros(n_trials)

    q_stage1_mf = np.zeros(2)          # for actions A,U
    q_stage2_mf = np.zeros((2, 2))     # for states X,Y and 2 aliens per state

    prev_a1 = None  # for perseveration

    kappa_centered = 2.0 * (kappa - 0.5)

    for t in range(n_trials):
        s = state[t]        # 0 or 1
        a1 = action_1[t]    # 0 or 1
        a2 = action_2[t]    # 0 or 1
        r = reward[t]

        max_q_stage2 = np.max(q_stage2_mf, axis=1)  # per state
        q_stage1_mb = transition_matrix @ max_q_stage2  # shape (2,)

        q1 = w * q_stage1_mb + (1.0 - w) * q_stage1_mf

        if prev_a1 is not None:
            bias = np.zeros(2)
            bias[prev_a1] = kappa_centered
            q1 = q1 + bias

        exp_q1 = np.exp(beta * (q1 - np.max(q1)))
        probs_1 = exp_q1 / np.sum(exp_q1)
        p_choice_1[t] = probs_1[a1]

        q2 = q_stage2_mf[s, :]
        exp_q2 = np.exp(beta * (q2 - np.max(q2)))
        probs_2 = exp_q2 / np.sum(exp_q2)
        p_choice_2[t] = probs_2[a2]


        delta2 = r - q_stage2_mf[s, a2]

        delta1 = q_stage2_mf[s, a2] - q_stage1_mf[a1]


        q_stage2_mf[s, a2] += alpha * delta2

        q_stage1_mf[a1] += alpha * delta1 + alpha * lam * delta2

        prev_a1 = a1

    eps = 1e-10
    neg_loglik = -(np.sum(np.log(p_choice_1 + eps)) + np.sum(np.log(p_choice_2 + eps)))
    return neg_loglik