def cognitive_model1(action_1, state, action_2, reward, stai, model_parameters):
    """Hybrid MB/MF with anxiety- and uncertainty-modulated arbitration plus MF decay.

    This model blends model-based (MB) and model-free (MF) values at stage 1.
    The arbitration weight w_t is shaped by:
    - baseline w0,
    - state of second-stage uncertainty (smaller alien value differences => higher MB weight),
    - anxiety (higher anxiety reduces MB reliance).
    Stage-2 uses MF Q-learning. MF values decay for unchosen actions to capture forgetting.

    Parameters (model_parameters):
    - alpha: [0,1] learning rate for MF updates at stage 2 and bootstrapped update to stage 1.
    - beta: [0,10] inverse temperature for both stages.
    - w0: [0,1] baseline MB weight at stage 1.
    - k_unc: [0,1] strength of uncertainty-driven increase in MB weight.
    - k_decay: [0,1] decay/forgetting of unupdated MF action values per trial.

    Inputs:
    - action_1: int array in {0,1}, chosen spaceship per trial.
    - state: int array in {0,1}, reached planet per trial.
    - action_2: int array in {0,1}, chosen alien per trial.
    - reward: float array, coins received per trial.
    - stai: array-like (length 1), anxiety score in [0,1].
    - model_parameters: list/array [alpha, beta, w0, k_unc, k_decay].

    Returns:
    - Negative log-likelihood of observed choices at both stages.
    """
    alpha, beta, w0, k_unc, k_decay = model_parameters
    n_trials = len(action_1)
    stai = float(stai[0])

    T = np.array([[0.7, 0.3],  # action 0 (A): P(X)=0.7, P(Y)=0.3
                  [0.3, 0.7]]) # action 1 (U): P(X)=0.3, P(Y)=0.7

    q1_mf = np.zeros(2)
    q2 = np.zeros((2, 2))  # state x action

    p1 = np.zeros(n_trials)
    p2 = np.zeros(n_trials)

    for t in range(n_trials):
        s = int(state[t])
        a1 = int(action_1[t])
        a2 = int(action_2[t])
        r = reward[t]

        diff_x = abs(q2[0, 0] - q2[0, 1])
        diff_y = abs(q2[1, 0] - q2[1, 1])

        unc = 1.0 - 0.5 * (np.tanh(diff_x) + np.tanh(diff_y))  # in (0,1), saturating

        w = w0 * (1.0 - 0.6 * stai) + k_unc * unc
        w = min(1.0, max(0.0, w))

        max_q2 = np.max(q2, axis=1)  # [X_best, Y_best]
        q1_mb = T @ max_q2

        q1_hybrid = (1.0 - w) * q1_mf + w * q1_mb

        logits1 = beta * q1_hybrid
        logits1 -= np.max(logits1)
        probs1 = np.exp(logits1)
        probs1 /= (np.sum(probs1) + 1e-16)
        p1[t] = probs1[a1]

        logits2 = beta * q2[s, :]
        logits2 -= np.max(logits2)
        probs2 = np.exp(logits2)
        probs2 /= (np.sum(probs2) + 1e-16)
        p2[t] = probs2[a2]


        delta2 = r - q2[s, a2]
        q2[s, a2] += alpha * delta2

        target1 = q2[s, a2]
        delta1 = target1 - q1_mf[a1]
        q1_mf[a1] += alpha * delta1

        other_a1 = 1 - a1
        q1_mf[other_a1] *= (1.0 - k_decay)

        other_a2 = 1 - a2
        q2[s, other_a2] *= (1.0 - k_decay)

        other_s = 1 - s
        q2[other_s, :] *= (1.0 - 0.5 * k_decay)

    eps = 1e-12
    nll = -(np.sum(np.log(p1 + eps)) + np.sum(np.log(p2 + eps)))
    return nll